# ShareGPT4Video: Improving Video Understanding and Generation with Better Captions

â­ï¸ [**Star to follow our team's projects !**](https://github.com/InternLM/InternLM-XComposer)

---

ğŸš€ğŸš€ğŸš€ Official implementation of **ShareGPT4Video: Improving Video Understanding and Generation with Better Captions**.

Here is an video for introducing ShareGPT4Video clearly:

[![Watch the video](https://img.youtube.com/vi/AQ7j3aegeeI/maxresdefault.jpg)](https://youtu.be/AQ7j3aegeeI)

- **Authors**: [Lin Chen*](https://lin-chen.site), [Xilin Wei*]() [Jinsong Li*](https://li-jinsong.github.io/), [Xiaoyi Dong](https://scholar.google.com/citations?user=FscToE0AAAAJ&hl=en), [Pan Zhang](https://panzhang0212.github.io/), [Yuhang Zang](https://yuhangzang.github.io/), [Zehui Chen](https://lovesnowbest.site/), [Haodong Duan](https://kennymckormick.github.io/), [Bin Lin](https://scholar.google.com.hk/citations?user=GCOVDKoAAAAJ&hl=en), [Zhenyu Tang](), [Li Yuan](https://yuanli2333.github.io/), [Dahua Lin](http://dahua.site/), [Feng ZhaoğŸ“§](https://scholar.google.com/citations?hl=en&user=r6CvuOUAAAAJ), [Jiaqi Wang ğŸ“§](https://myownskyw7.github.io/)
- **Institutes**: University of Science and Technology of China; Shanghai AI Laboratory; Peking University;
- **Resources**: [[Paper]()] [[Project Page](https://sharegpt4video.github.io/)] [[ShareGPT4Video Dataset]()]
- **Models**: [[ShareGPT4Video-8B]()] [[ShareGPT4Video-34B]()] [[ShareCaptioner-Video]()]
- **Demo**: [[ğŸ¤—ShareGPT4Video-8B]()] [[ğŸ¤—ShareCaptioner-Video]()]

## ğŸ’¡ Highlights

- ğŸ”¥ A **large-scale** **highly descriptive** video-text dataset, **40K** GPT4-Vision-generated video captions, around **400K** implicit video split captions
- ğŸ”¥ A **general video captioner for various video durations, resolutions, aspect ratios**, approaching GPT4-Vision's caption capability, featuring two inference mode targeted for quality and efficiency, separately.
- ğŸ”¥ A series of superior large multi-modal models **ShareGPT4Video-8B**, **ShareGPT4Video-34B**, lasting **1 hour** and **5 hours** on 32xA100 GPUs of training respectively.
- ğŸ”¥ **Improving Text-to-Video performance** with high-quality video captions generate by our ShareCaptioner-Video

## ğŸ“œ News

**[2024/5/26]** The [ShareGPT4Video dataset](https://huggingface.co/datasets/ShareGPT4Video/ShareGPT4Video) and [project page](https://sharegpt4video.github.io/) are released!

## ğŸ‘¨â€ğŸ’» Todo

- [ ] Training and evaluation code for ShareGPT4V-8B, ShareGPT4Vidoe-34B
- [ ] Local ShareCaptioner-Video
- [ ] Web demo and local demo of ShareGPT4V-8B
- [ ] Checkpoints of ShareGPT4Vidoe-8B, ShareGPT4Vidoe-34B

## â¤ï¸ Acknowledgments
- [LLaVA](https://github.com/haotian-liu/LLaVA): the codebase we built upon. Thanks for their wonderful work.
- [Open-Sora-Plan](https://github.com/PKU-YuanGroup/Open-Sora-Plan): a excellent open-source codebase for Sora-like text-to-video implementation. Thanks for their wonderful work.
