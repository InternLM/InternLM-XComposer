import os
import re
import sys
sys.path.insert(0, '.')
sys.path.insert(0, '..')

import argparse
import gradio as gr
os.environ["GRADIO_TEMP_DIR"] = os.path.join(os.getcwd(), 'tmp')
import copy
import time
from datetime import datetime
import hashlib
import shutil
import requests
from PIL import Image, ImageFile
import torch
from torchvision import transforms
from torchvision.transforms.functional import InterpolationMode
import transformers
from transformers import AutoModelForCausalLM, AutoTokenizer

ImageFile.LOAD_TRUNCATED_IMAGES = True

from demo_asset.assets.css_html_js import custom_css
from demo_asset.serve_utils import Stream, Iteratorize
from demo_asset.conversation import CONV_VISION_INTERN2
from demo_asset.download import download_image_thread
from examples.utils import get_stopping_criteria, set_random_seed


meta_instruction = """You are an AI assistant whose name is InternLM-XComposer (æµ¦è¯­Â·çµç¬”).
- InternLM-XComposer (æµ¦è¯­Â·çµç¬”) is a conversational language model that is developed by Shanghai AI Laboratory (ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤). It is designed to be helpful, honest, and harmless.
- InternLM-XComposer (æµ¦è¯­Â·çµç¬”) can understand and communicate fluently in the language chosen by the user such as English and ä¸­æ–‡.
"""
chat_meta = """You are an AI assistant whose name is InternLM-XComposer (æµ¦è¯­Â·çµç¬”).
- InternLM-XComposer (æµ¦è¯­Â·çµç¬”) is a multi-modality conversational language model that is developed by Shanghai AI Laboratory (ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤). It is designed to be helpful, honest, and harmless.
- InternLM-XComposer (æµ¦è¯­Â·çµç¬”) can understand and communicate fluently in the language chosen by the user such as English and ä¸­æ–‡.
- InternLM-XComposer (æµ¦è¯­Â·çµç¬”) is capable of comprehending and articulating responses effectively based on the provided image.
"""



max_section = 60
chat_stream_output = True
article_stream_output = True


def get_urls(caption, exclude):
    headers = {'Content-Type': 'application/json'}
    json_data = {'caption': caption, 'exclude': exclude, 'need_idxs': True}
    response = requests.post('https://lingbi.openxlab.org.cn/image/similar',
                             headers=headers,
                             json=json_data)
    urls = response.json()['data']['image_urls']
    idx = response.json()['data']['indices']
    return urls, idx


class ImageGroup(object):
    def __init__(self, cap, paths, pts=0):
        #assert len(paths) == 1 or len(paths) == 4, f"ImageGroup only support 1 or 4 images, not {len(paths)} images"
        self.cap = cap
        self.paths = paths
        self.pts = pts

    def __str__(self):
        return f"cap: {self.cap}; paths:{self.paths}; pts:{self.pts}"


class ImageProcessor:
    def __init__(self, image_size=224):
        mean = (0.48145466, 0.4578275, 0.40821073)
        std = (0.26862954, 0.26130258, 0.27577711)
        self.normalize = transforms.Normalize(mean, std)

        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size),
                              interpolation=InterpolationMode.BICUBIC),
            transforms.ToTensor(),
            self.normalize,
        ])

    def __call__(self, item):
        if isinstance(item, str):
            item = Image.open(item).convert('RGB')
        return self.transform(item)

class Demo_UI:
    def __init__(self, code_path, num_gpus=1):
        self.code_path = code_path
        self.reset()

        tokenizer = AutoTokenizer.from_pretrained(code_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(code_path, device_map='cuda', trust_remote_code=True).half().eval()
        self.model.tokenizer = tokenizer
        self.model.vit.resize_pos()

        self.vis_processor = ImageProcessor()

        stop_words_ids = [92397]
        #stop_words_ids = [92542]
        self.stopping_criteria = get_stopping_criteria(stop_words_ids)
        set_random_seed(1234)
        self.r2 = re.compile(r'<Seg[0-9]*>')
        self.withmeta = False

    def reset(self):
        self.pt = 0
        self.img_pt = 0
        self.texts_imgs = []
        self.open_edit = False
        self.hash_folder = '12345'
        self.instruction = ''

    def text2instruction(self, text):
        if self.withmeta:
            return f"[UNUSED_TOKEN_146]system\n{meta_instruction}[UNUSED_TOKEN_145]\n[UNUSED_TOKEN_146]user\n{text}[UNUSED_TOKEN_145]\n[UNUSED_TOKEN_146]assistant\n"
        else:
            return f"[UNUSED_TOKEN_146]user\n{text}[UNUSED_TOKEN_145]\n[UNUSED_TOKEN_146]assistant\n"

    def get_images_xlab(self, caption, pt, exclude):
        urls, idxs = get_urls(caption.strip()[:53], exclude)
        print(urls[0])
        print('download image with url')
        download_image_thread(urls,
                              folder='articles/' + self.hash_folder,
                              index=pt,
                              num_processes=4)
        print('image downloaded')
        return idxs

    def generate(self, text, random, beam, max_length, repetition):
        with torch.no_grad():
            with torch.cuda.amp.autocast():
                input_ids = self.model.tokenizer(text, return_tensors="pt")['input_ids']
                len_input_tokens = len(input_ids[0])

                generate = self.model.generate(input_ids.cuda(),
                                                do_sample=random,
                                                num_beams=beam,
                                                temperature=1.,
                                                repetition_penalty=float(repetition),
                                                stopping_criteria=self.stopping_criteria,
                                                max_new_tokens=max_length,
                                                top_p=0.8,
                                                top_k=40,
                                                length_penalty=1.0)
        response = generate[0].tolist()
        response = response[len_input_tokens:]
        response = self.model.tokenizer.decode(response, skip_special_tokens=True)
        response = response.replace('[UNUSED_TOKEN_145]', '')
        response = response.replace('[UNUSED_TOKEN_146]', '')
        return response

    def generate_with_emb(self, emb, random, beam, max_length, repetition, im_mask=None):
        with torch.no_grad():
            with torch.cuda.amp.autocast():
                generate = self.model.generate(inputs_embeds=emb,
                                                do_sample=random,
                                                num_beams=beam,
                                                temperature=1.,
                                                repetition_penalty=float(repetition),
                                                stopping_criteria=self.stopping_criteria,
                                                max_new_tokens=max_length,
                                                top_p=0.8,
                                                top_k=40,
                                                length_penalty=1.0,
                                                im_mask=im_mask)
        response = generate[0].tolist()
        response = self.model.tokenizer.decode(response, skip_special_tokens=True)
        response = response.replace('[UNUSED_TOKEN_145]', '')
        response = response.replace('[UNUSED_TOKEN_146]', '')
        return response


    def generate_article(self, question, beam, repetition, max_length, random, seed, outline=None):
        if outline is None:
            instruction = f'è¯·åˆ—å‡ºä¸‹é¢çš„ä½œæ–‡é¢˜ç›®å¯¹åº”çš„å†™ä½œå¤§çº²ã€‚\n**é¢˜ç›®ï¼š**\n{question}'
            top_p = 0.8
        else:
            instruction = f'æ ¹æ®ä¸‹é¢çš„é¢˜ç›®å’Œå†™ä½œå¤§çº²è¿›è¡Œå†™ä½œã€‚\n**é¢˜ç›®**\n{question}\n\n**å¤§çº²ï¼š**\n{outline}\n\n**æ­£æ–‡å†™ä½œï¼š**\n'
            top_p = 1.0

        self.reset()
        set_random_seed(int(seed))
        self.hash_folder = hashlib.sha256(instruction.encode()).hexdigest()
        self.instruction = instruction

        text = self.text2instruction(instruction)
        print('random generate:{}'.format(random))
        if article_stream_output:
            input_ids = self.model.tokenizer(text, return_tensors="pt")['input_ids']
            input_embeds = self.model.model.tok_embeddings(input_ids.cuda())
            im_mask = None

            print(text)
            generate_params = dict(
                inputs_embeds=input_embeds,
                do_sample=random,
                stopping_criteria=self.stopping_criteria,
                repetition_penalty=float(repetition),
                max_new_tokens=max_length,
                top_p=top_p,
                top_k=40,
                length_penalty=1.0,
                im_mask=im_mask,
            )
            output_text = "â–Œ"
            with self.generate_with_streaming(**generate_params) as generator:
                for output in generator:
                    decoded_output = self.model.tokenizer.decode(output[1:])
                    if output[-1] in [self.model.tokenizer.eos_token_id, 92542]:
                        break
                    output_text = decoded_output.replace('\n', '\n\n') + "â–Œ"
                    yield output_text
                    time.sleep(0.01)
            output_text = output_text[:-1]
            yield output_text
        else:
            output_text = self.generate(text, random, beam, max_length, repetition)
            return output_text


    def save(self, beam, repetition, text_num, random, seed):
        folder = 'save_articles/' + self.hash_folder
        if os.path.exists(folder):
            for item in os.listdir(folder):
                os.remove(os.path.join(folder, item))
        os.makedirs(folder, exist_ok=True)

        save_text = '\n'.join([self.instruction, str(beam), str(repetition), str(text_num), str(random), str(seed)]) + '\n\n'
        if len(self.texts_imgs) > 0:
            for txt, img in self.texts_imgs:
                save_text += txt + '\n'
                if img is not None:
                    save_text += f'<div align="center"> <img src={os.path.basename(img.paths[img.pts])} width = 500/> </div>'
                    path = os.path.join('articles', self.hash_folder, os.path.basename(img.paths[img.pts]))
                    if os.path.exists(path):
                        shutil.copy(path, folder)
                    else:
                        shutil.copy(img.paths[img.pts], folder)

        with open(os.path.join(folder, 'io.MD'), 'w') as f:
            f.writelines(save_text)

        archived = shutil.make_archive(folder, 'zip', folder)
        return archived

    def generate_with_callback(self, callback=None, **kwargs):
        kwargs.setdefault("stopping_criteria",
                          transformers.StoppingCriteriaList())
        kwargs["stopping_criteria"].append(Stream(callback_func=callback))
        with torch.no_grad():
            self.model.generate(**kwargs)

    def generate_with_streaming(self, **kwargs):
        return Iteratorize(self.generate_with_callback, kwargs, callback=None)

    def change_meta(self, withmeta):
        self.withmeta = withmeta


parser = argparse.ArgumentParser()
#parser.add_argument("--code_path", default='internlm/internlm-xcomposer2-7b')
parser.add_argument("--code_path", default='/mnt/hwfile/mllm/zangyuhang/share_models/7b_v4')
parser.add_argument("--private", default=False, action='store_true')
parser.add_argument("--num_gpus", default=1, type=int)
parser.add_argument("--port", default=11111, type=int)
args = parser.parse_args()
demo_ui = Demo_UI(args.code_path, args.num_gpus)


with gr.Blocks(css=custom_css, title='æµ¦è¯­Â·çµç¬” (InternLM-XComposer)') as demo:
    with gr.Row():
        with gr.Column(scale=20):
            # gr.HTML("""<h1 align="center" id="space-title" style="font-size:35px;">ğŸ¤— æµ¦è¯­Â·çµç¬” (InternLM-XComposer)</h1>""")
            gr.HTML(
                """<h1 align="center"><img src="https://raw.githubusercontent.com/InternLM/InternLM-XComposer/main/assets/logo-zuowen.png", alt="InternLM-XComposer" border="0" style="margin: 0 auto; height: 120px;" /></a> </h1>"""
            )
            gr.HTML(
                """<p>Internlm-xcomposer2-ä½œæ–‡ æ˜¯åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­2å’Œä¹¦ç”ŸÂ·æµ¦è¯­Â·çµç¬”2ç ”å‘çš„ä½œæ–‡æ¨¡å‹ã€‚å®ƒé‡‡ç”¨å…ˆå†™ä½œæ–‡å¤§çº²ï¼Œå†æ ¹æ®å¤§çº²å±•å¼€çš„å†™ä½œæ–¹å¼ï¼Œèƒ½å¤Ÿæ¸…æ™°åœ°æ¢³ç†æ–‡ç« è„‰ç»œï¼Œä½¿æ–‡ç« ç»“æ„æ›´ä¸¥è°¨ã€‚æ¬¢è¿å¤§å®¶è¯•ç”¨å¹¶æå‡ºå®è´µæ„è§ï¼Œæˆ‘ä»¬å°†æŒç»­ä¼˜åŒ–ï¼Œä¸ºå¹¿å¤§ç”¨æˆ·å¸¦æ¥æ›´å¥½çš„ä½œæ–‡ä½“éªŒã€‚</p>"""
            )

    with gr.Row():
        with gr.Column(scale=2):
            instruction = gr.Textbox(label='ä½œæ–‡é¢˜ç›®',
                                     lines=5,
                                     value='''é˜…è¯»ä¸‹é¢çš„ææ–™ï¼Œæ ¹æ®è¦æ±‚å†™ä½œã€‚
éšç€äº’è”ç½‘çš„æ™®åŠã€äººå·¥æ™ºèƒ½çš„åº”ç”¨ï¼Œè¶Šæ¥è¶Šå¤šçš„é—®é¢˜èƒ½å¾ˆå¿«å¾—åˆ°ç­”æ¡ˆã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬çš„é—®é¢˜æ˜¯å¦ä¼šè¶Šæ¥è¶Šå°‘ï¼Ÿ
ä»¥ä¸Šææ–™å¼•å‘äº†ä½ æ€æ ·çš„è”æƒ³å’Œæ€è€ƒï¼Ÿè¯·å†™ä¸€ç¯‡æ–‡ç« ã€‚
è¦æ±‚ï¼šé€‰å‡†è§’åº¦ï¼Œç¡®å®šç«‹æ„ï¼Œæ˜ç¡®æ–‡ä½“ï¼Œè‡ªæ‹Ÿæ ‡é¢˜ï¼›ä¸è¦å¥—ä½œï¼Œä¸å¾—æŠ„è¢­ï¼›ä¸å¾—æ³„éœ²ä¸ªäººä¿¡æ¯ï¼›ä¸å°‘äº800å­—ã€‚''', elem_classes='edit')
        with gr.Column(scale=1):
            seed = gr.Slider(minimum=1.0, maximum=20000.0, value=8909.0, step=1.0, label='Random Seed (éšæœºç§å­)')
            btn = gr.Button("Submit (æäº¤)", scale=1)

    with gr.Row():
        with gr.Column(scale=1):
            with gr.Accordion("Advanced Settings (é«˜çº§è®¾ç½®)", open=False, visible=True) as parameter_article:
                beam = gr.Slider(minimum=1.0, maximum=6.0, value=1.0, step=1.0, label='Beam Size (é›†æŸå¤§å°)')
                repetition = gr.Slider(minimum=1.0, maximum=2.0, value=1.005, step=0.001, label='Repetition_penalty (é‡å¤æƒ©ç½š)')
                text_num = gr.Slider(minimum=100.0, maximum=4096.0, value=4096.0, step=1.0, label='Max output tokens (æœ€å¤šè¾“å‡ºå­—æ•°)')
                random = gr.Checkbox(value=True, label='Sampling (éšæœºé‡‡æ ·)')
                withmeta = gr.Checkbox(value=False, label='With Meta (ä½¿ç”¨metaæŒ‡ä»¤)')

    province = gr.Markdown(visible=False)

    gr.Examples(
        examples=[['2024 æ–°è¯¾æ ‡Iå·', '''é˜…è¯»ä¸‹é¢çš„ææ–™ï¼Œæ ¹æ®è¦æ±‚å†™ä½œã€‚
éšç€äº’è”ç½‘çš„æ™®åŠã€äººå·¥æ™ºèƒ½çš„åº”ç”¨ï¼Œè¶Šæ¥è¶Šå¤šçš„é—®é¢˜èƒ½å¾ˆå¿«å¾—åˆ°ç­”æ¡ˆã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬çš„é—®é¢˜æ˜¯å¦ä¼šè¶Šæ¥è¶Šå°‘ï¼Ÿ
ä»¥ä¸Šææ–™å¼•å‘äº†ä½ æ€æ ·çš„è”æƒ³å’Œæ€è€ƒï¼Ÿè¯·å†™ä¸€ç¯‡æ–‡ç« ã€‚
è¦æ±‚ï¼šé€‰å‡†è§’åº¦ï¼Œç¡®å®šç«‹æ„ï¼Œæ˜ç¡®æ–‡ä½“ï¼Œè‡ªæ‹Ÿæ ‡é¢˜ï¼›ä¸è¦å¥—ä½œï¼Œä¸å¾—æŠ„è¢­ï¼›ä¸å¾—æ³„éœ²ä¸ªäººä¿¡æ¯ï¼›ä¸å°‘äº800å­—ã€‚'''],
                  ['2024 æ–°è¯¾æ ‡IIå·', '''é˜…è¯»ä¸‹é¢çš„ææ–™ï¼Œæ ¹æ®è¦æ±‚å†™ä½œã€‚
æœ¬è¯•å·ç°ä»£æ–‡é˜…è¯»Iæåˆ°ï¼Œé•¿ä¹…ä»¥æ¥ï¼Œäººä»¬åªèƒ½çœ‹åˆ°æœˆçƒå›ºå®šæœå‘åœ°çƒçš„ä¸€é¢ï¼Œâ€œå«¦å¨¥å››å·â€æ¢æœˆä»»åŠ¡æ­å¼€äº†æœˆèƒŒçš„ç¥ç§˜é¢çº±ï¼›éšç€â€œå¤©é—®ä¸€å·â€é£ç¦»åœ°çƒï¼Œèˆªå¤©äººçš„ç›®å…‰åˆæŠ•å‘é¥è¿œçš„æ·±ç©ºâ€¦â€¦
æ­£å¦‚äººç±»çš„å¤ªç©ºä¹‹æ—…ï¼Œæˆ‘ä»¬æ¯ä¸ªäººä¹Ÿéƒ½åœ¨ä¸æ–­æŠµè¾¾æœªçŸ¥ä¹‹å¢ƒã€‚
è¿™å¼•å‘äº†ä½ æ€æ ·çš„è”æƒ³ä¸æ€è€ƒï¼Ÿè¯·å†™ä¸€ç¯‡æ–‡ç« ã€‚
è¦æ±‚ï¼šé€‰å‡†è§’åº¦ï¼Œç¡®å®šç«‹æ„ï¼Œæ˜ç¡®æ–‡ä½“ï¼Œè‡ªæ‹Ÿæ ‡é¢˜ï¼›ä¸è¦å¥—ä½œï¼Œä¸å¾—æŠ„è¢­ï¼›ä¸å¾—æ³„éœ²ä¸ªäººä¿¡æ¯ï¼›ä¸å°‘äº800å­—ã€‚'''],
                  ['2024 åŒ—äº¬å·', '''å‡ åƒå¹´æ¥ï¼Œå¤è€çš„ç»å…¸å¸¸è¯»å¸¸æ–°ï¼Œæ°å‡ºçš„æ€æƒ³å¸¸ç”¨å¸¸æ–°ï¼Œä¸­åæ°‘æ—çš„ä¼Ÿå¤§ç²¾ç¥äº˜å¤å¸¸æ–°â€¦â€¦å¾ˆå¤šäº‹ç‰©ï¼Œåœ¨æ—¶é—´çš„æ·¬ç‚¼ä¸­ï¼Œæ„ˆæ˜¾æ´»åŠ›å’Œä»·å€¼ã€‚è¯·ä»¥â€œå†ä¹…å¼¥æ–°â€ä¸ºé¢˜ç›®ï¼Œå†™ä¸€ç¯‡è®®è®ºæ–‡ã€‚è¦æ±‚ï¼šè®ºç‚¹æ˜ç¡®ï¼Œè®ºæ®å……åˆ†ï¼Œè®ºè¯åˆç†ï¼›è¯­è¨€æµç•…ï¼Œä¹¦å†™æ¸…æ™°ã€‚'''],
                  ['2024 å¤©æ´¥å·', '''é˜…è¯»ä¸‹é¢çš„ææ–™ï¼Œæ ¹æ®è¦æ±‚å†™ä½œã€‚
åœ¨ç¼¤çº·çš„ä¸–ç•Œä¸­ï¼Œæ— è®ºæ˜¯ä¸ªäººã€ç¾¤ä½“è¿˜æ˜¯å›½å®¶ï¼Œéƒ½ä¼šé¢å¯¹åˆ«äººå¯¹æˆ‘ä»¬çš„å®šä¹‰ã€‚æˆ‘ä»¬è¦è®¤çœŸå¯¹å¾…â€œè¢«å®šä¹‰â€ï¼Œæ˜è¾¨æ˜¯éï¼Œå»èŠœå­˜çœŸï¼Œä¸ºè‡ªå·±çš„æå‡åŠ©åŠ›ï¼›ä¹Ÿè¦å‹‡äºé€šè¿‡â€œè‡ªå®šä¹‰â€æ¥å¡‘é€ è‡ªæˆ‘ï¼Œå½°æ˜¾é£åï¼Œç”¨è‡ªå·±çš„æ–¹å¼å‰è¿›ã€‚
ä»¥ä¸Šææ–™èƒ½å¼•å‘ä½ æ€æ ·çš„è”æƒ³ä¸æ€è€ƒï¼Ÿè¯·ç»“åˆä½ çš„ä½“éªŒå’Œæ„Ÿæ‚Ÿï¼Œå†™ä¸€ç¯‡æ–‡ç« ã€‚
è¦æ±‚ï¼šâ‘ è‡ªé€‰è§’åº¦ï¼Œè‡ªæ‹Ÿæ ‡é¢˜ï¼›â‘¡æ–‡ä½“ä¸é™ï¼ˆè¯—æ­Œé™¤å¤–ï¼‰ï¼Œæ–‡ä½“ç‰¹å¾æ˜æ˜¾ï¼›â‘¢ä¸å°‘äº800å­—ï¼›â‘£ä¸å¾—æŠ„è¢­ï¼Œä¸å¾—å¥—ä½œã€‚'''],
                  ['2024 ä¸Šæµ·å·', '''ç”Ÿæ´»ä¸­ï¼Œäººä»¬å¸¸ç”¨è®¤å¯åº¦åˆ¤åˆ«äº‹ç‰©ï¼ŒåŒºåˆ†é«˜ä¸‹ã€‚è¯·å†™ä¸€ç¯‡æ–‡ç« ï¼Œè°ˆè°ˆä½ å¯¹â€œè®¤å¯åº¦â€çš„è®¤è¯†å’Œæ€è€ƒã€‚è¦æ±‚ï¼šï¼ˆ1ï¼‰è‡ªæ‹Ÿé¢˜ç›®ï¼›ï¼ˆ2ï¼‰ä¸å°‘äº800å­—ã€‚''']],
        inputs=[province, instruction],
    )

    outline = gr.Textbox(label='æ–‡ç« å¤§çº²', lines=3, max_lines=8)
    #article = gr.Textbox(label='ä½œæ–‡', lines=10, max_lines=20, elem_classes='feedback')
    #gr.Markdown(value='æ–‡ç« åˆ›ä½œ:', elem_classes='feedback')
    article = gr.Markdown(label='ä½œæ–‡', elem_classes='feedback')

    btn.click(demo_ui.generate_article,
        inputs=[instruction, beam, repetition, text_num, random, seed], outputs=outline).then(
        demo_ui.generate_article, inputs=[instruction, beam, repetition, text_num, random, seed, outline], outputs=article)



if __name__ == "__main__":
    if args.private:
        demo.queue().launch(share=False, server_name="127.0.0.1", server_port=args.port, max_threads=1)
    else:
        demo.queue().launch(share=True, server_name="0.0.0.0", server_port=args.port, max_threads=1)

