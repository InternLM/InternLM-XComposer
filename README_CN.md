<p align="center">
    <img src="logo.png" width="400"/>
</p>
<p align="center">
    <b><font size="6">æµ¦è¯­Â·çµç¬”</font></b>
</p>

<!-- <div align="center">
        InternLM-XComposer <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp ï½œ InternLM-VL <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp | Technical Report <a href=""> <a> ğŸ“„  -->

<div align="center">
        InternLM-XComposer <a href="https://huggingface.co/internlm/internlm-xcomposer-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b">ğŸ¤– </a> &nbsp ï½œ InternLM-XComposer-VL <a href="https://huggingface.co/internlm/internlm-xcomposer-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b">ğŸ¤– </a> &nbsp | Technical Report <a href="https://arxiv.org/pdf/2309.15112.pdf">  ğŸ“„ </a>

[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_CN.md)

</div>

<br>



**æµ¦è¯­Â·çµç¬”**æ˜¯åŸºäº[ä¹¦ç”ŸÂ·æµ¦è¯­](https://github.com/InternLM/InternLM/tree/main)å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„è§†è§‰-è¯­è¨€å¤§æ¨¡å‹ï¼Œæä¾›å‡ºè‰²çš„å›¾æ–‡ç†è§£å’Œåˆ›ä½œèƒ½åŠ›ï¼Œå…·æœ‰å¤šé¡¹ä¼˜åŠ¿ï¼š

- **å›¾æ–‡äº¤é”™åˆ›ä½œ**: æµ¦è¯­Â·çµç¬”å¯ä»¥ä¸ºç”¨æˆ·æ‰“é€ å›¾æ–‡å¹¶è²Œçš„ä¸“å±æ–‡ç« ã€‚ç”Ÿæˆçš„æ–‡ç« æ–‡é‡‡æ–ç„¶ï¼Œå›¾æ–‡ç›¸å¾—ç›Šå½°ï¼Œæä¾›æ²‰æµ¸å¼çš„é˜…è¯»ä½“éªŒã€‚è¿™ä¸€èƒ½åŠ›ç”±ä»¥ä¸‹æ­¥éª¤å®ç°ï¼š
    1. **ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œåˆ›ä½œç¬¦åˆè¦æ±‚çš„é•¿æ–‡ç« **ã€‚
    2. **æ™ºèƒ½åˆ†ææ–‡ç« ï¼Œè‡ªåŠ¨è§„åˆ’æ’å›¾çš„ç†æƒ³ä½ç½®ï¼Œç¡®å®šå›¾åƒå†…å®¹éœ€æ±‚ã€‚**
    3. **å¤šå±‚æ¬¡æ™ºèƒ½ç­›é€‰ï¼Œä»å›¾åº“ä¸­é”å®šæœ€å®Œç¾çš„å›¾ç‰‡ã€‚**

- **åŸºäºä¸°å¯Œå¤šæ¨¡æ€çŸ¥è¯†çš„å›¾æ–‡ç†è§£**: æµ¦è¯­Â·çµç¬”è®¾è®¡äº†é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œä¸ºæ¨¡å‹æ³¨å…¥æµ·é‡çš„å¤šæ¨¡æ€æ¦‚å¿µå’ŒçŸ¥è¯†æ•°æ®ï¼Œèµ‹äºˆå…¶å¼ºå¤§çš„å›¾æ–‡ç†è§£å’Œå¯¹è¯èƒ½åŠ›ã€‚
- **æ°å‡ºæ€§èƒ½**: æµ¦è¯­Â·çµç¬”åœ¨å¤šé¡¹è§†è§‰è¯­è¨€å¤§æ¨¡å‹çš„ä¸»æµè¯„æµ‹ä¸Šå‡å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒ…æ‹¬[MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation) (è‹±æ–‡è¯„æµ‹), [MMBench](https://opencompass.org.cn/leaderboard-multimodal) (è‹±æ–‡è¯„æµ‹), [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard) (è‹±æ–‡è¯„æµ‹), [CCBench](https://opencompass.org.cn/leaderboard-multimodal)(ä¸­æ–‡è¯„æµ‹), [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal) (ä¸­æ–‡è¯„æµ‹).

æˆ‘ä»¬å¼€æºçš„æµ¦è¯­Â·çµç¬”åŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬:

- **InternLM-XComposer-VL-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b">ğŸ¤– </a>: åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­å¤§è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€é¢„è®­ç»ƒå’Œå¤šä»»åŠ¡è®­ç»ƒæ¨¡å‹ï¼Œåœ¨å¤šç§è¯„æµ‹ä¸Šè¡¨ç°å‡ºæ°å‡ºæ€§èƒ½, ä¾‹å¦‚ï¼šMME Benchmark, MMBench Seed-Bench, CCBench, MMBench-CN.
- **InternLM-XComposer-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b">ğŸ¤– </a>: é¢å‘ *å›¾æ–‡äº¤é”™æ–‡ç« åˆ›ä½œ* å’Œ *æ™ºèƒ½å¯¹è¯* çš„å¾®è°ƒæ¨¡å‹ã€‚
 
æ›´å¤šæ–¹æ³•ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf)ï¼
  <br>

<!-- 
<p align="center">
    <figcaption align = "center"><b> InternLM-XComposer </b></figcaption>
<p> -->

## Demo



https://github.com/InternLM/InternLM-XComposer/assets/22662425/0a2b475b-3f74-4f41-a5df-796680fa56cd






## æ›´æ–°æ¶ˆæ¯
* ```2023.10.8``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b) å·²åœ¨Modelscopeå¼€æº. 
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer-VL-7B**çš„[è¯„æµ‹ä»£ç ](./evaluation/)å·²å¼€æº.
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) å·²åœ¨Hugging Faceå¼€æº. 
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf).
<br>

## è¯„æµ‹

æˆ‘ä»¬åœ¨5ä¸ªå¤šæ¨¡æ€è¯„æµ‹ä¸Šæµ‹è¯• InternLM-XComposer-VL çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è‹±æ–‡è¯„æµ‹ [MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation), [MMBench](https://opencompass.org.cn/leaderboard-multimodal), [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard) å’Œä¸­æ–‡è¯„æµ‹ [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal), [CCBench](https://opencompass.org.cn/leaderboard-multimodal).

   - [MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation): åŒ…æ‹¬14ä¸ªå­ä»»åŠ¡çš„å¤šæ¨¡æ€æ¨¡å‹å…¨é¢è¯„æµ‹ã€‚
   - [MMBench](https://opencompass.org.cn/leaderboard-multimodal): æä¾›ç²¾å¿ƒæ”¶é›†çš„å¤šæ¨¡æ€è¯„æµ‹é¢˜ç›®å’Œä½¿ç”¨ChatGPTçš„å¾ªç¯è¯„ä¼°ç­–ç•¥çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚
   - [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal): ç®€ä½“ä¸­æ–‡ç‰ˆæœ¬é—®é¢˜å’Œç­”æ¡ˆçš„ [MMBench](https://opencompass.org.cn/leaderboard-multimodal) è¯„æµ‹ã€‚
   - [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard): åŒ…æ‹¬äººå·¥æ ‡æ³¨çš„1.9ä¸‡é“å¤šæ¨¡æ€å¤šé€‰é¢˜ç›®çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚
   - [CCBench](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation): é’ˆå¯¹ä¸­å›½æ–‡åŒ–ç†è§£çš„ä¸­æ–‡å¤šæ¨¡æ€è¯„æµ‹ã€‚

InternLM-XComposer-VL åœ¨**å…¨éƒ¨5ä¸ªè¯„æµ‹**ä¸Šå‡è¶…è¿‡å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚


### MME Benchmark

[MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation) æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹è®¾è®¡çš„å¤šæ¨¡æ€è¯„æµ‹ï¼Œå…³æ³¨æ¨¡å‹çš„æ„ŸçŸ¥å’Œè®¤çŸ¥èƒ½åŠ›ï¼ŒåŒ…æ‹¬14ä¸ªå­ä»»åŠ¡ã€‚

InternLM-XComposer-VL åœ¨æ„ŸçŸ¥å’Œè®¤çŸ¥èƒ½åŠ›çš„ç»¼åˆæ€§èƒ½ä¸Šè¶…è¿‡å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/mme/MME_Bench.md)ã€‚


<p align="center">
ç»¼åˆæ€§èƒ½
</p>


<div align="center">

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | [InternLM-XComposer-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM-7B](https://github.com/InternLM/InternLM-XComposer) | 1919.5 |
|   2  | Qwen-VL-Chat    |        Qwen-7B            | 1848.3 |
|   3  |      MMICL      |         FlanT5xxl        | 1810.7 |
|   4  |    Skywork-MM   |      Skywork-MM-13B      | 1775.5 |
|   5  |       BLIVA     |    FlanT5xxl             | 1669.2 |

</div>



<p align="center">
    <img src="evaluation/mme/perception.PNG" width="600"/>
</p>
<p align="center">
    <img src="evaluation/mme/cognition.PNG" width="600"/>
</p>


### MMBench & MMBench-CN

[MMBench](https://opencompass.org.cn/leaderboard-multimodal) æä¾›ç²¾å¿ƒæ”¶é›†çš„å¤šæ¨¡æ€è¯„æµ‹é¢˜ç›®å’Œä½¿ç”¨ChatGPTçš„å¾ªç¯è¯„ä¼°ç­–ç•¥ï¼ŒåŒ…æ‹¬äº†20ä¸ªèƒ½åŠ›é¡¹ã€‚MMBench è¿˜æä¾›äº†ä¸­æ–‡ç‰ˆçš„ MMBench-CN ç”¨äºæµ‹è¯•æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ã€‚

InternLM-XComposer-VL åœ¨ MMBench å’Œ MMBench-CN æµ‹è¯•é›†ä¸Šéƒ½å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/mmbench/MMBench.md).


<p align="center">
MMBench æµ‹è¯•é›†æ€§èƒ½
</p>

<div align='center'>

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 74.4 |
|   2  |    Pink  |        Vicuna-7B            | 74.1 |
|   3  |      JiuTian      |        FLANT5-XXL        | 71.8 |
|   4  |  WeMM   |      InternLM-7B      | 69.0 |
|   5  |     mPLUG-Owl     |    LLaMA2 7B            |  68.5 |

</div>

<p align="center">
    <img src="evaluation/mmbench/mmbench.PNG" width="1000"/>
</p>

<p align="center">
MMBench-CN æµ‹è¯•é›†æ€§èƒ½
</p>

<div align='center'>

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 72.4 |
|   2  |    QWen-VL-Chat | Qwen-7B | 56.3 |
|   3  |    LLaVA       | LLaMA 7B  |36.6 |
|   4  |    VosualGLM   | ChatGLM 6B | 25.6 |
|   5  |    mPLUG-Owl | LLaMA2 7B  | 24.9 |

</div>

<p align="center">
    <img src="evaluation/mmbench/mmbench_cn.PNG" width="1000"/>
</p>

### SEED-Bench

[SEED-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard) æä¾›åŒ…æ‹¬äººå·¥æ ‡æ³¨çš„1.9ä¸‡é“å¤šæ¨¡æ€å¤šé€‰é¢˜ç›®çš„å¤šæ¨¡æ€è¯„æµ‹, è¦†ç›–12ä¸ªè¯„æµ‹ä¸ºåº¦ã€‚SEED-BenchåŒæ—¶æä¾› *å›¾åƒ* å’Œ *è§†é¢‘* ç†è§£èƒ½åŠ›è¯„æµ‹ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/seed_bench/SEED.md).

InternLM-XComposer-VL åœ¨å›¾åƒç†è§£è¯„æµ‹å–å¾—æœ€ä½³æ€§èƒ½ã€‚


<p align="center">
SeedBench å›¾åƒç†è§£è¯„æµ‹
</p>

<div align="center">

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 66.9 |
|   2  |    QWen-VL-Chat | Qwen-7B | 65.4 |
|   3  |    QWen-VL | Qwen-7B | 62.3 |
|   4  |    InstructBLIP-Vicuna   |        Vicuna 7B  | 58.8 |
|   5  |    InstructBLIP   |     Flan-T5-XL  | 57.8 |

</div>

<p align="center">
    <img src="evaluation/seed_bench/seed_bench.PNG" width="1000"/>
</p>

### CCBench

[CCBench](https://opencompass.org.cn/leaderboard-multimodal) é’ˆå¯¹ä¸­å›½æ–‡åŒ–ç†è§£è®¾è®¡çš„å¤šæ¨¡æ€è¯„æµ‹. ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/seed_bench/MMBench.md).

<p align="center">
CCBench è¯„æµ‹
</p>

<div align="center">

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 47.6 |
|   2  |    QWen-VL-Chat | Qwen-7B | 39.3 |
|   3  |    mPLUG-Owl | LLaMA2 7B  | 12.9 |
|   3  |    InstructBLIP       |        Vicuna 7B  | 12.1 |
|   4  |    VosualGLM   | ChatGLM 6B | 9.2  |

</div>

<p align="center">
    <img src="evaluation/mmbench/ccbench.PNG" width="1000"/>
</p>

## ç¯å¢ƒè¦æ±‚

* python 3.8 and above
* pytorch 1.12 and above, 2.0 and above are recommended
* CUDA 11.4 and above are recommended (this is for GPU users)
  <br>

## å®‰è£…æ•™ç¨‹

åœ¨è¿è¡Œä»£ç ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§è¦æ±‚é…ç½®ç¯å¢ƒã€‚è¯·ç¡®è®¤ä½ çš„è®¾å¤‡ç¬¦åˆä»¥ä¸Šç¯å¢ƒéœ€æ±‚ï¼Œç„¶åå®‰è£…ç¯å¢ƒã€‚
è¯·å‚è€ƒ[å®‰è£…æ•™ç¨‹](docs/install_CN.md)

## å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•å®ç”¨çš„ ğŸ¤— Transformers ç‰ˆæœ¬ InternLM-XComposer çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚

#### ğŸ¤— Transformers

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# 'é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥ï¼1955å¹´4æœˆ18æ—¥ï¼‰ï¼Œå¾·å›½è£”ç‘å£«ç±ç‰©ç†å­¦å®¶ã€‚ä»–åˆ›ç«‹äº†ç°ä»£ç‰©ç†å­¦çš„ä¸¤å¤§æ”¯æŸ±ç†è®ºï¼š
# ç›¸å¯¹è®ºå’Œé‡å­åŠ›å­¦ï¼Œ è€Œè´¨èƒ½ç­‰ä»·å…¬å¼E=mc2ä¾¿æ˜¯ä»–çš„ç›¸å¯¹è®ºæ€æƒ³çš„æ˜è¯ï¼Œå› è€Œè¢«å…¬è®¤ä¸ºæ˜¯ç»§ä¼½åˆ©ç•¥ã€ç‰›é¡¿ä¹‹åæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ã€‚
# 1999å¹´ï¼Œçˆ±å› æ–¯å¦è¢«ç¾å›½ã€Šæ—¶ä»£å‘¨åˆŠã€‹è¯„é€‰ä¸º20ä¸–çºªçš„â€œä¸–çºªäººç‰©â€ï¼Œä»–åœ¨ç‰©ç†å­¦ä¸Šçš„è´¡çŒ®ï¼Œä½¿ä»–åœ¨ä¸–ç•Œå„åœ°å—åˆ°äººä»¬çš„å°Šæ•¬ã€‚'

# Single-Turn Text-Image Dialogue
text = 'è¯·é—®è¿™å¼ å›¾ç‰‡é‡Œé¢çš„äººæ˜¯è°ï¼Ÿå¹¶ä»‹ç»ä¸‹ä»–ã€‚'
image = 'examples/images/aiyinsitan.jpg'
response = model.generate(text, image)
print(response)
# å›¾ç‰‡ä¸­çš„ç”·å­æ˜¯é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼‰ï¼Œä¸€ä½è‘—åçš„ç‰©ç†å­¦å®¶å’Œç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·çš„ä¹Œå°”å§†å¸‚ï¼Œ
# 1955 å¹´4æœˆ18æ—¥é€ä¸–äºç¾å›½æ–°æ³½è¥¿å·æ™®æ—æ–¯é¡¿å¸‚ã€‚çˆ±å› æ–¯å¦åœ¨20ä¸–çºªåˆæå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œå¯¹ç°ä»£ç‰©ç†å­¦çš„å‘å±•äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚

# Multi-Turn Text-Image Dialogue
# 1st turn
text = 'å›¾ç‰‡é‡Œé¢çš„æ˜¯è°ï¼Ÿ'
response, history = model.chat(text=text, image=image, history=None)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ã€‚

# 2nd turn
text = 'ä»–æœ‰å“ªäº›æˆå°±?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ï¼Œä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œå¯¹ç°ä»£ç‰©ç†å­¦çš„å‘å±•äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚
# æ­¤å¤–ï¼Œä»–è¿˜æå‡ºäº†è‘—åçš„è´¨èƒ½æ–¹ç¨‹E=mcÂ²ï¼Œä¸ºæ ¸èƒ½çš„å¼€å‘æä¾›äº†ç†è®ºåŸºç¡€ã€‚

# 3rd turn
text = 'ä»–æ˜¯æœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶å—?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# æ˜¯çš„ï¼Œé˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ã€‚
```

#### ğŸ¤– ModelScope

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-xcomposer-7b')
model = AutoModel.from_pretrained(model_dir, trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# 'é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥ï¼1955å¹´4æœˆ18æ—¥ï¼‰ï¼Œå¾·å›½è£”ç‘å£«ç±ç‰©ç†å­¦å®¶ã€‚ä»–åˆ›ç«‹äº†ç°ä»£ç‰©ç†å­¦çš„ä¸¤å¤§æ”¯æŸ±ç†è®ºï¼š
# ç›¸å¯¹è®ºå’Œé‡å­åŠ›å­¦ï¼Œ è€Œè´¨èƒ½ç­‰ä»·å…¬å¼E=mc2ä¾¿æ˜¯ä»–çš„ç›¸å¯¹è®ºæ€æƒ³çš„æ˜è¯ï¼Œå› è€Œè¢«å…¬è®¤ä¸ºæ˜¯ç»§ä¼½åˆ©ç•¥ã€ç‰›é¡¿ä¹‹åæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ã€‚
# 1999å¹´ï¼Œçˆ±å› æ–¯å¦è¢«ç¾å›½ã€Šæ—¶ä»£å‘¨åˆŠã€‹è¯„é€‰ä¸º20ä¸–çºªçš„â€œä¸–çºªäººç‰©â€ï¼Œä»–åœ¨ç‰©ç†å­¦ä¸Šçš„è´¡çŒ®ï¼Œä½¿ä»–åœ¨ä¸–ç•Œå„åœ°å—åˆ°äººä»¬çš„å°Šæ•¬ã€‚'
```

## Demo

### Web UI

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè½»æ¾æ­å»º Web UI demo çš„ä»£ç .

<p align="center">
    <img src="demo_asset/assets/UI_en.png" width="800"/>
</p>


è¯·è¿è¡Œä»¥ä¸‹ä»£ç 

```
python examples/web_demo.py
```
æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ Web UI [ç”¨æˆ·æŒ‡å—](demo_asset/demo.md).

<br>

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ª star :star: å’Œ å¼•ç”¨ :pencil: :)

```BibTeX
@misc{zhang2023internlmxcomposer,
      title={InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition}, 
      author={Pan Zhang and Xiaoyi Dong and Bin Wang and Yuhang Cao and Chao Xu and Linke Ouyang and Zhiyuan Zhao and Shuangrui Ding and Songyang Zhang and Haodong Duan and Hang Yan and Xinyue Zhang and Wei Li and Jingwen Li and Kai Chen and Conghui He and Xingcheng Zhang and Yu Qiao and Dahua Lin and Jiaqi Wang},
      year={2023},
      eprint={2309.15112},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

<br>

## è®¸å¯è¯ & è”ç³»æˆ‘ä»¬

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚
