<p align="center">
    <img src="logo.png" width="400"/>
</p>
<p align="center">
    <b><font size="6">æµ¦è¯­Â·çµç¬”</font></b>
</p>

<!-- <div align="center">
        InternLM-XComposer <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp ï½œ InternLM-VL <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp | Technical Report <a href=""> <a> ğŸ“„  -->

<div align="center">
        InternLM-XComposer <a href="https://huggingface.co/internlm/internlm-xcomposer-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b">ğŸ¤– </a> &nbsp ï½œ InternLM-XComposer-VL <a href="https://huggingface.co/internlm/internlm-xcomposer-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b">ğŸ¤– </a> &nbsp | Technical Report <a href="https://arxiv.org/pdf/2309.15112.pdf">  ğŸ“„ </a>

[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_CN.md)

</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> å’Œ <a href="https://github.com/InternLM/InternLM/assets/25839884/a6aad896-7232-4220-ac84-9e070c2633ce" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>
</p>

<br>



**æµ¦è¯­Â·çµç¬”**æ˜¯åŸºäº[ä¹¦ç”ŸÂ·æµ¦è¯­](https://github.com/InternLM/InternLM/tree/main)å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„è§†è§‰-è¯­è¨€å¤§æ¨¡å‹ï¼Œæä¾›å‡ºè‰²çš„å›¾æ–‡ç†è§£å’Œåˆ›ä½œèƒ½åŠ›ï¼Œå…·æœ‰å¤šé¡¹ä¼˜åŠ¿ï¼š

- **å›¾æ–‡äº¤é”™åˆ›ä½œ**: æµ¦è¯­Â·çµç¬”å¯ä»¥ä¸ºç”¨æˆ·æ‰“é€ å›¾æ–‡å¹¶è²Œçš„ä¸“å±æ–‡ç« ã€‚ç”Ÿæˆçš„æ–‡ç« æ–‡é‡‡æ–ç„¶ï¼Œå›¾æ–‡ç›¸å¾—ç›Šå½°ï¼Œæä¾›æ²‰æµ¸å¼çš„é˜…è¯»ä½“éªŒã€‚è¿™ä¸€èƒ½åŠ›ç”±ä»¥ä¸‹æ­¥éª¤å®ç°ï¼š
    1. **ç†è§£ç”¨æˆ·æŒ‡ä»¤ï¼Œåˆ›ä½œç¬¦åˆè¦æ±‚çš„é•¿æ–‡ç« **ã€‚
    2. **æ™ºèƒ½åˆ†ææ–‡ç« ï¼Œè‡ªåŠ¨è§„åˆ’æ’å›¾çš„ç†æƒ³ä½ç½®ï¼Œç¡®å®šå›¾åƒå†…å®¹éœ€æ±‚ã€‚**
    3. **å¤šå±‚æ¬¡æ™ºèƒ½ç­›é€‰ï¼Œä»å›¾åº“ä¸­é”å®šæœ€å®Œç¾çš„å›¾ç‰‡ã€‚**

- **åŸºäºä¸°å¯Œå¤šæ¨¡æ€çŸ¥è¯†çš„å›¾æ–‡ç†è§£**: æµ¦è¯­Â·çµç¬”è®¾è®¡äº†é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œä¸ºæ¨¡å‹æ³¨å…¥æµ·é‡çš„å¤šæ¨¡æ€æ¦‚å¿µå’ŒçŸ¥è¯†æ•°æ®ï¼Œèµ‹äºˆå…¶å¼ºå¤§çš„å›¾æ–‡ç†è§£å’Œå¯¹è¯èƒ½åŠ›ã€‚
- **æ°å‡ºæ€§èƒ½**: æµ¦è¯­Â·çµç¬”åœ¨å¤šé¡¹è§†è§‰è¯­è¨€å¤§æ¨¡å‹çš„ä¸»æµè¯„æµ‹ä¸Šå‡å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒ…æ‹¬[MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation) (è‹±æ–‡è¯„æµ‹), [MMBench](https://opencompass.org.cn/leaderboard-multimodal) (è‹±æ–‡è¯„æµ‹), [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard) (è‹±æ–‡è¯„æµ‹), [CCBench](https://opencompass.org.cn/leaderboard-multimodal)(ä¸­æ–‡è¯„æµ‹), [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal) (ä¸­æ–‡è¯„æµ‹).

æˆ‘ä»¬å¼€æºçš„æµ¦è¯­Â·çµç¬”åŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬:

- **InternLM-XComposer-VL-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b">ğŸ¤– </a>: åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­å¤§è¯­è¨€æ¨¡å‹çš„å¤šæ¨¡æ€é¢„è®­ç»ƒå’Œå¤šä»»åŠ¡è®­ç»ƒæ¨¡å‹ï¼Œåœ¨å¤šç§è¯„æµ‹ä¸Šè¡¨ç°å‡ºæ°å‡ºæ€§èƒ½, ä¾‹å¦‚ï¼šMME Benchmark, MMBench Seed-Bench, CCBench, MMBench-CN.
- **InternLM-XComposer-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b">ğŸ¤– </a>: é¢å‘ *å›¾æ–‡äº¤é”™æ–‡ç« åˆ›ä½œ* å’Œ *æ™ºèƒ½å¯¹è¯* çš„å¾®è°ƒæ¨¡å‹ã€‚
 
æ›´å¤šæ–¹æ³•ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf)ï¼
  <br>

<!-- 
<p align="center">
    <figcaption align = "center"><b> InternLM-XComposer </b></figcaption>
<p> -->

## Demo



https://github.com/InternLM/InternLM-XComposer/assets/22662425/0a2b475b-3f74-4f41-a5df-796680fa56cd






## æ›´æ–°æ¶ˆæ¯
* ```2023.10.30``` ğŸ‰ğŸ‰ğŸ‰ çµç¬”åœ¨[Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards) å’Œ [Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation) å–å¾—äº†ç¬¬ä¸€å.
* ```2023.10.19``` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒå¤šå¡æµ‹è¯•ï¼Œå¤šå¡Demo. ä¸¤å¼ 4090æ˜¾å¡å¯éƒ¨ç½²å…¨é‡Demo.
* ```2023.10.12``` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒ4æ¯”ç‰¹é‡åŒ–Demoï¼Œ æ¨¡å‹æ–‡ä»¶å¯ä»[Hugging Face](https://huggingface.co/internlm/internlm-xcomposer-7b-4bit) and [ModelScope](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b-4bit) è·å–
* ```2023.10.8``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b) å·²åœ¨Modelscopeå¼€æº. 
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer-VL-7B**çš„[è¯„æµ‹ä»£ç ](./evaluation/)å·²å¼€æº.
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) å·²åœ¨Hugging Faceå¼€æº. 
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf).
<br>

## è¯„æµ‹

æˆ‘ä»¬åœ¨7ä¸ªå¤šæ¨¡æ€è¯„æµ‹ä¸Šæµ‹è¯• InternLM-XComposer-VL çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬è‹±æ–‡è¯„æµ‹ [MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation), [MMBench](https://opencompass.org.cn/leaderboard-multimodal), [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard), [Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards), [Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation) å’Œä¸­æ–‡è¯„æµ‹ [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal), [CCBench](https://opencompass.org.cn/leaderboard-multimodal).

   - [MME Benchmark](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation): åŒ…æ‹¬14ä¸ªå­ä»»åŠ¡çš„å¤šæ¨¡æ€æ¨¡å‹å…¨é¢è¯„æµ‹ã€‚
   - [MMBench](https://opencompass.org.cn/leaderboard-multimodal): æä¾›ç²¾å¿ƒæ”¶é›†çš„å¤šæ¨¡æ€è¯„æµ‹é¢˜ç›®å’Œä½¿ç”¨ChatGPTçš„å¾ªç¯è¯„ä¼°ç­–ç•¥çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚
   - [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal): ç®€ä½“ä¸­æ–‡ç‰ˆæœ¬é—®é¢˜å’Œç­”æ¡ˆçš„ [MMBench](https://opencompass.org.cn/leaderboard-multimodal) è¯„æµ‹ã€‚
   - [Seed-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard): åŒ…æ‹¬äººå·¥æ ‡æ³¨çš„1.9ä¸‡é“å¤šæ¨¡æ€å¤šé€‰é¢˜ç›®çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚
   - [CCBench](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation): é’ˆå¯¹ä¸­å›½æ–‡åŒ–ç†è§£çš„ä¸­æ–‡å¤šæ¨¡æ€è¯„æµ‹ã€‚
   - [Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards): è¯„æµ‹å¤šæ¨¡æ€å¤§æ¨¡å‹çš„low-levelè§†è§‰èƒ½åŠ›ã€‚
   - [Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation): ä»LVLM-eHubæ‹†åˆ†å‡ºæ¥çš„ï¼Œå¤šèƒ½åŠ›å±‚æ¬¡çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚

InternLM-XComposer-VL åœ¨**å…¨éƒ¨7ä¸ªè¯„æµ‹**ä¸Šå‡è¶…è¿‡å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚


### MME Benchmark

[MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation) æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹è®¾è®¡çš„å¤šæ¨¡æ€è¯„æµ‹ï¼Œå…³æ³¨æ¨¡å‹çš„æ„ŸçŸ¥å’Œè®¤çŸ¥èƒ½åŠ›ï¼ŒåŒ…æ‹¬14ä¸ªå­ä»»åŠ¡ã€‚

InternLM-XComposer-VL åœ¨æ„ŸçŸ¥å’Œè®¤çŸ¥èƒ½åŠ›çš„ç»¼åˆæ€§èƒ½ä¸Šè¶…è¿‡å…¶ä»–å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/mme/MME_Bench.md)ã€‚


<p align="center">
ç»¼åˆæ€§èƒ½
</p>


<div align="center">

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | [InternLM-XComposer-VL](https://github.com/InternLM/InternLM-XComposer) | [InternLM-7B](https://github.com/InternLM/InternLM-XComposer) | 1919.5 |
|   2  | Qwen-VL-Chat    |        Qwen-7B            | 1848.3 |
|   3  |      MMICL      |         FlanT5xxl        | 1810.7 |
|   4  |    Skywork-MM   |      Skywork-MM-13B      | 1775.5 |
|   5  |       BLIVA     |    FlanT5xxl             | 1669.2 |

</div>


<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/mme/perception.PNG" width="600"/>
</p>
<p align="center">
    <img src="evaluation/mme/cognition.PNG" width="600"/>
</p>
</details>



### MMBench & MMBench-CN

[MMBench](https://opencompass.org.cn/leaderboard-multimodal) æä¾›ç²¾å¿ƒæ”¶é›†çš„å¤šæ¨¡æ€è¯„æµ‹é¢˜ç›®å’Œä½¿ç”¨ChatGPTçš„å¾ªç¯è¯„ä¼°ç­–ç•¥ï¼ŒåŒ…æ‹¬äº†20ä¸ªèƒ½åŠ›é¡¹ã€‚MMBench è¿˜æä¾›äº†ä¸­æ–‡ç‰ˆçš„ MMBench-CN ç”¨äºæµ‹è¯•æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ã€‚

InternLM-XComposer-VL åœ¨ MMBench å’Œ MMBench-CN æµ‹è¯•é›†ä¸Šéƒ½å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/mmbench/MMBench.md).


<p align="center">
MMBench æµ‹è¯•é›†æ€§èƒ½
</p>

<div align='center'>

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 74.4 |
|   2  |    Pink  |        Vicuna-7B            | 74.1 |
|   3  |      JiuTian      |        FLANT5-XXL        | 71.8 |
|   4  |  WeMM   |      InternLM-7B      | 69.0 |
|   5  |     mPLUG-Owl     |    LLaMA2 7B            |  68.5 |

</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/mmbench/mmbench.PNG" width="1000"/>
</p>
</details>

<p align="center">
MMBench-CN æµ‹è¯•é›†æ€§èƒ½
</p>

<div align='center'>

| æ’å |          æ¨¡å‹           |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 72.4 |
|   2  |     QWen-VL-Chat      | Qwen-7B | 56.3 |
|   3  |         LLaVA         | LLaMA 7B  |36.6 |
|   4  |       VisualGLM       | ChatGLM 6B | 25.6 |
|   5  |       mPLUG-Owl       | LLaMA2 7B  | 24.9 |

</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/mmbench/mmbench_cn.PNG" width="1000"/>
</p>
</details>



### SEED-Bench

[SEED-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard) æä¾›åŒ…æ‹¬äººå·¥æ ‡æ³¨çš„1.9ä¸‡é“å¤šæ¨¡æ€å¤šé€‰é¢˜ç›®çš„å¤šæ¨¡æ€è¯„æµ‹, è¦†ç›–12ä¸ªè¯„æµ‹ä¸ºåº¦ã€‚SEED-BenchåŒæ—¶æä¾› *å›¾åƒ* å’Œ *è§†é¢‘* ç†è§£èƒ½åŠ›è¯„æµ‹ã€‚ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/seed_bench/SEED.md).

InternLM-XComposer-VL åœ¨å›¾åƒç†è§£è¯„æµ‹å–å¾—æœ€ä½³æ€§èƒ½ã€‚


<p align="center">
SeedBench å›¾åƒç†è§£è¯„æµ‹
</p>

<div align="center">

| æ’å |      æ¨¡å‹      |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 66.9 |
|   2  |    QWen-VL-Chat | Qwen-7B | 65.4 |
|   3  |    QWen-VL | Qwen-7B | 62.3 |
|   4  |    InstructBLIP-Vicuna   |        Vicuna 7B  | 58.8 |
|   5  |    InstructBLIP   |     Flan-T5-XL  | 57.8 |

</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/seed_bench/seed_bench.PNG" width="1000"/>
</p>
</details>



### CCBench

[CCBench](https://opencompass.org.cn/leaderboard-multimodal) é’ˆå¯¹ä¸­å›½æ–‡åŒ–ç†è§£è®¾è®¡çš„å¤šæ¨¡æ€è¯„æµ‹. ç‚¹å‡»æŸ¥çœ‹[æ›´å¤šä¿¡æ¯](evaluation/seed_bench/MMBench.md).

<p align="center">
CCBench è¯„æµ‹
</p>

<div align="center">

| æ’å |          æ¨¡å‹           |          ç‰ˆæœ¬         |  åˆ†æ•°  |
|:----:|:---------------------:|:------------------------:|:-------:|
| ï¸  1  | InternLM-XComposer-VL | InternLM-7B | 47.6 |
|   2  |     QWen-VL-Chat      | Qwen-7B | 39.3 |
|   3  |       mPLUG-Owl       | LLaMA2 7B  | 12.9 |
|   3  |     InstructBLIP      |        Vicuna 7B  | 12.1 |
|   4  |       VisualGLM       | ChatGLM 6B | 9.2  |

</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/mmbench/ccbench.PNG" width="1000"/>
</p>
</details>



### Q-Bench

[Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards) æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•å¤šæ¨¡æ€å¤§æ¨¡å‹çš„low-levelè§†è§‰èƒ½åŠ›çš„è¯„æµ‹ã€‚

<p align="center">
Q-Bench è¯„æµ‹
</p>

<div align="center">

|  æ’å  |           A1ï¼šæ„ŸçŸ¥ (dev)            |           A1ï¼šæ„ŸçŸ¥ (test)           |              A2: æè¿°              |                  A3: è¯„ä¼°                  | 
|:----:|:--------------------------------:|:--------------------------------:|:--------------------------------:|:----------------------------------------:|
| ï¸  1 | InternLM-XComposer-VL<br/>0.6535 | InternLM-XComposer-VL<br/>0.6435 | InternLM-XComposer-VL<br/>4.21/6 | InternLM-XComposer-VL<br/>(0.542, 0.581) |
|  2   |    LLaVA-v1.5-13B<br/>0.6214     |   InstrucBLIP-T5-XL<br/>0.6194   |       Kosmos-2<br/>4.03/6        |        Qwen-VL<br/>(0.475, 0.506)        |
|  3   |   InstrucBLIP-T5-XL<br/>0.6147   |        Qwen-VL<br/>0.6167        |       mPLUG-Owl<br/>3.94/6       |    LLaVA-v1.5-13B<br/>(0.444, 0.473)     |


</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/qbench/overall.png" width="1000"/>
</p>
</details>



### Tiny LVLM

[Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation) æ˜¯ä¸€ä¸ªä»LVLM-eHubæ‹†åˆ†å‡ºæ¥çš„ï¼Œå¤šèƒ½åŠ›å±‚æ¬¡çš„å¤šæ¨¡æ€è¯„æµ‹ã€‚

<p align="center">
Tiny LVLM è¯„æµ‹
</p>

<div align="center">

| æ’å |          æ¨¡å‹           |          ç‰ˆæœ¬         |  åˆ†æ•°  | 
|:----:|:---------------------:|:------------:|:------:|
| ï¸  1 | InternLM-XComposer-VL | InternLM-7B  | 322.51 |
|  2   |         Bard          |     Bard     | 319.59 |
|  3   |     Qwen-VL-Chat      | Qwen-VL-Chat | 316.81 |


</div>

<details>
  <summary>
    <b>leaderboard</b>
  </summary>
<p align="center">
    <img src="evaluation/tiny_lvlm/overall.png" width="1000"/>
</p>
</details>


## ç¯å¢ƒè¦æ±‚

* python 3.8 and above
* pytorch 1.12 and above, 2.0 and above are recommended
* CUDA 11.4 and above are recommended (this is for GPU users)
  <br>

## å®‰è£…æ•™ç¨‹

åœ¨è¿è¡Œä»£ç ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§è¦æ±‚é…ç½®ç¯å¢ƒã€‚è¯·ç¡®è®¤ä½ çš„è®¾å¤‡ç¬¦åˆä»¥ä¸Šç¯å¢ƒéœ€æ±‚ï¼Œç„¶åå®‰è£…ç¯å¢ƒã€‚
è¯·å‚è€ƒ[å®‰è£…æ•™ç¨‹](docs/install_CN.md)

## å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•å®ç”¨çš„ ğŸ¤— Transformers ç‰ˆæœ¬ InternLM-XComposer çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚

<details>
  <summary>
    <b>ğŸ¤— Transformers</b>
  </summary>


```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥-1955å¹´4æœˆ18æ—¥ï¼‰æ˜¯å¾·å›½å‡ºç”Ÿçš„ç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œ
# è¿™ä¸¤ä¸ªç†è®ºå¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚çˆ±å› æ–¯å¦è¿˜å‘ç°äº†å…‰ç”µæ•ˆåº”å®šå¾‹ï¼Œå¹¶å› æ­¤è·å¾—äº†1921å¹´çš„è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚
# çˆ±å› æ–¯å¦äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·ä¹Œå°”å§†å¸‚çš„ä¸€ä¸ªçŠ¹å¤ªäººå®¶åº­ã€‚ä»–åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦å’Œæ•°å­¦ï¼Œ # å¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œå…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå…‰ç”µæ•ˆåº”å®šå¾‹ã€‚
# 1915å¹´ï¼Œçˆ±å› æ–¯å¦å‘è¡¨äº†å¹¿ä¹‰ç›¸å¯¹è®ºï¼Œè¯¥ç†è®ºè§£é‡Šäº†å¼•åŠ›æ˜¯å¦‚ä½•é€šè¿‡æ—¶ç©ºå¼¯æ›²æ¥å½±å“ç‰©ä½“çš„è¿åŠ¨ã€‚è¿™ä¸€ç†è®ºæ”¹å˜äº†äººä»¬å¯¹å®‡å®™çš„è®¤è¯†ï¼Œå¹¶ä¸ºç°ä»£å®‡å®™å­¦å¥ å®šäº†åŸºç¡€ã€‚
# 1933å¹´ï¼Œçˆ±å› æ–¯å¦å› ä¸ºä»–çš„çŠ¹å¤ªè¡€ç»Ÿè€Œå—åˆ°çº³ç²¹å…šçš„è¿«å®³ï¼Œè¢«è¿«ç¦»å¼€å¾·å›½ã€‚ä»–æœ€ç»ˆå®šå±…åœ¨ç¾å›½ï¼Œå¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ä½™ç”Ÿã€‚1955å¹´4æœˆ18æ—¥ï¼Œçˆ±å› æ–¯å¦åœ¨æ™®æ—æ–¯é¡¿å»ä¸–ï¼Œäº«å¹´76å²ã€‚
# çˆ±å› æ–¯å¦çš„è´¡çŒ®å¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ï¼Œä»–è¢«è®¤ä¸ºæ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç§‘å­¦å®¶ä¹‹ä¸€ã€‚

# Single-Turn Text-Image Dialogue
text = 'è¯·é—®è¿™å¼ å›¾ç‰‡é‡Œé¢çš„äººæ˜¯è°ï¼Ÿå¹¶ä»‹ç»ä¸‹ä»–ã€‚'
image = 'examples/images/aiyinsitan.jpg'
response = model.generate(text, image)
print(response)
# å›¾ç‰‡é‡Œçš„äººæ˜¯é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼‰ï¼Œä¸€ä½è‘—åçš„ç‰©ç†å­¦å®¶å’Œç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·çš„ä¹Œå°”å§†å¸‚ï¼Œ
# å¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ ç«¥å¹´å’Œå°‘å¹´æ—¶ä»£ã€‚çˆ±å› æ–¯å¦åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦ï¼Œå¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œ
# å…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œè´¨èƒ½æ–¹ç¨‹E=mc^2ã€‚1921å¹´ï¼Œçˆ±å› æ–¯å¦è·å¾—äº†è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œä»¥è¡¨å½°ä»–å¯¹å…‰ç”µæ•ˆåº”çš„å‘ç°å’Œå¯¹ç‹­ä¹‰ç›¸å¯¹è®ºçš„è´¡çŒ®ã€‚

# Multi-Turn Text-Image Dialogue
# 1st turn
text = 'å›¾ç‰‡é‡Œé¢çš„æ˜¯è°ï¼Ÿ'
response, history = model.chat(text=text, image=image, history=None)
print(response)
# å›¾ç‰‡é‡Œé¢çš„äººç‰©æ˜¯é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼‰ï¼Œä¸€ä½è‘—åçš„ç‰©ç†å­¦å®¶å’Œç†è®ºç‰©ç†å­¦å®¶ã€‚

# 2nd turn
text = 'ä»–æœ‰å“ªäº›æˆå°±?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ï¼Œä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œä¸ºç°ä»£ç‰©ç†å­¦çš„å‘å±•åšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ã€‚
# æ­¤å¤–ï¼Œä»–è¿˜æå‡ºäº†å…‰é‡å­ç†è®ºã€è´¨èƒ½å…³ç³»ç­‰é‡è¦ç†è®ºï¼Œå¯¹ç°ä»£ç‰©ç†å­¦çš„å‘å±•äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚

# 3rd turn
text = 'ä»–æ˜¯æœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶å—?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# æ˜¯çš„ï¼Œé˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œä¸ºç°ä»£ç‰©ç†å­¦çš„å‘å±•åšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ã€‚
```
</details>


<details>
  <summary>
    <b>ğŸ¤– ModelScope</b>
  </summary>


```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-xcomposer-7b')
model = AutoModel.from_pretrained(model_dir, trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥-1955å¹´4æœˆ18æ—¥ï¼‰æ˜¯å¾·å›½å‡ºç”Ÿçš„ç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œ
# è¿™ä¸¤ä¸ªç†è®ºå¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚çˆ±å› æ–¯å¦è¿˜å‘ç°äº†å…‰ç”µæ•ˆåº”å®šå¾‹ï¼Œå¹¶å› æ­¤è·å¾—äº†1921å¹´çš„è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚
# çˆ±å› æ–¯å¦äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·ä¹Œå°”å§†å¸‚çš„ä¸€ä¸ªçŠ¹å¤ªäººå®¶åº­ã€‚ä»–åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦å’Œæ•°å­¦ï¼Œ # å¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œå…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå…‰ç”µæ•ˆåº”å®šå¾‹ã€‚
# 1915å¹´ï¼Œçˆ±å› æ–¯å¦å‘è¡¨äº†å¹¿ä¹‰ç›¸å¯¹è®ºï¼Œè¯¥ç†è®ºè§£é‡Šäº†å¼•åŠ›æ˜¯å¦‚ä½•é€šè¿‡æ—¶ç©ºå¼¯æ›²æ¥å½±å“ç‰©ä½“çš„è¿åŠ¨ã€‚è¿™ä¸€ç†è®ºæ”¹å˜äº†äººä»¬å¯¹å®‡å®™çš„è®¤è¯†ï¼Œå¹¶ä¸ºç°ä»£å®‡å®™å­¦å¥ å®šäº†åŸºç¡€ã€‚
# 1933å¹´ï¼Œçˆ±å› æ–¯å¦å› ä¸ºä»–çš„çŠ¹å¤ªè¡€ç»Ÿè€Œå—åˆ°çº³ç²¹å…šçš„è¿«å®³ï¼Œè¢«è¿«ç¦»å¼€å¾·å›½ã€‚ä»–æœ€ç»ˆå®šå±…åœ¨ç¾å›½ï¼Œå¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ä½™ç”Ÿã€‚1955å¹´4æœˆ18æ—¥ï¼Œçˆ±å› æ–¯å¦åœ¨æ™®æ—æ–¯é¡¿å»ä¸–ï¼Œäº«å¹´76å²ã€‚
# çˆ±å› æ–¯å¦çš„è´¡çŒ®å¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ï¼Œä»–è¢«è®¤ä¸ºæ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç§‘å­¦å®¶ä¹‹ä¸€ã€‚
```
</details>


## Web UI

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè½»æ¾æ­å»º Web UI demo çš„ä»£ç .

<p align="center">
    <img src="demo_asset/assets/UI_en.png" width="800"/>
</p>


è¯·è¿è¡Œä»¥ä¸‹ä»£ç ï¼ˆéœ€è¦>=32GBæ˜¾å­˜çš„GPU, æ¨èï¼‰

```
python examples/web_demo.py
```
æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ Web UI [ç”¨æˆ·æŒ‡å—](demo_asset/demo.md)ã€‚ å¦‚æœæ‚¨æƒ³è¦æ›´æ”¹æ¨¡å‹å­˜æ”¾çš„æ–‡ä»¶å¤¹ï¼Œè¯·ä½¿ç”¨ --folder=new_folder é€‰é¡¹ã€‚

## é‡åŒ–
æˆ‘ä»¬æä¾›4bité‡åŒ–æ¨¡å‹æ¥ç¼“è§£æ¨¡å‹çš„å†…å­˜éœ€æ±‚ã€‚ è¦è¿è¡Œ4bitæ¨¡å‹ï¼ˆGPUå†…å­˜> = 12GBï¼‰ï¼Œæ‚¨éœ€è¦é¦–å…ˆå®‰è£…ç›¸åº”çš„[ä¾èµ–åŒ…](docs/install_CN.md)ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡ŒèŠå¤©å’Œç½‘é¡µæ¼”ç¤ºï¼š
```
# 4-bit chat
python examples/example_chat_4bit.py
# 4-bit web demo
python examples/web_demo_4bit.py
```

## å¤šGPUæµ‹è¯•
å¦‚æœä½ æœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: pip install accelerateï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡ŒèŠå¤©å’Œç½‘é¡µæ¼”ç¤ºï¼š
```
# chat with 2 GPUs
python examples/example_chat.py --num_gpus 2
# web demo with 2 GPUs
python examples/web_demo.py --num_gpus 2
```
<br>

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ª star :star: å’Œ å¼•ç”¨ :pencil: :)

```BibTeX
@misc{zhang2023internlmxcomposer,
      title={InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition}, 
      author={Pan Zhang and Xiaoyi Dong and Bin Wang and Yuhang Cao and Chao Xu and Linke Ouyang and Zhiyuan Zhao and Shuangrui Ding and Songyang Zhang and Haodong Duan and Hang Yan and Xinyue Zhang and Wei Li and Jingwen Li and Kai Chen and Conghui He and Xingcheng Zhang and Yu Qiao and Dahua Lin and Jiaqi Wang},
      year={2023},
      eprint={2309.15112},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

<br>

## è®¸å¯è¯ & è”ç³»æˆ‘ä»¬

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚
