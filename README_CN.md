<p align="center">
    <img src="./assets/logo_cn.png" width="400"/>
</p>
<p align="center">
    <b><font size="6">æµ¦è¯­Â·çµç¬”2</font></b>
</p>

<!-- <div align="center">
        InternLM-XComposer <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp ï½œ InternLM-VL <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp | Technical Report <a href=""> <a> ğŸ“„  -->

<div align="center">
        InternLM-XComposer2 <a href="https://huggingface.co/internlm/internlm-xcomposer2-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b"><img src="./assets/modelscope_logo.png" width="20px"></a> &nbspï½œ InternLM-XComposer2-VL <a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b"><img src="./assets/modelscope_logo.png" width="20px"></a> &nbsp | æŠ€æœ¯æŠ¥å‘Š <a href="">  ğŸ“„ </a>

[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_CN.md)


<p align="center">
    æ„Ÿè°¢ç¤¾åŒºæä¾›çš„ InternLM-XComposer2 <a href="https://huggingface.co/spaces/Willow123/InternLM-XComposer">åœ¨çº¿è¯•ç”¨</a>
</p>

</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> å’Œ <a href="https://github.com/InternLM/InternLM/assets/25839884/a6aad896-7232-4220-ac84-9e070c2633ce" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>
</p>

<br>

## æœ¬ä»“åº“åŒ…æ‹¬çš„å¤šæ¨¡æ€é¡¹ç›®

> [**InternLM-XComposer2**](https://github.com/InternLM/InternLM-XComposer): **Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Models**

> [**InternLM-XComposer**](https://github.com/InternLM/InternLM-XComposer/tree/main/InternLM-XComposer-1.0): **A Vision-Language Large Model for Advanced Text-image Comprehension and Composition**

> <img src="https://raw.githubusercontent.com/ShareGPT4V/ShareGPT4V-Resources/master/images/logo_tight.png" style="vertical-align: -20px;" :height="25px" width="25px">[**ShareGPT4V**](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V): **Improving Large Multi-modal Models with Better Captions**

</br>



**æµ¦è¯­Â·çµç¬”2**æ˜¯åŸºäº[ä¹¦ç”ŸÂ·æµ¦è¯­2](https://github.com/InternLM/InternLM/tree/main)å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„çªç ´æ€§çš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå…·æœ‰éå‡¡çš„å›¾æ–‡å†™ä½œå’Œå›¾åƒç†è§£èƒ½åŠ›ï¼Œåœ¨å¤šç§åº”ç”¨åœºæ™¯è¡¨ç°å‡ºè‰²ï¼š

- **è‡ªç”±æŒ‡ä»¤è¾“å…¥çš„å›¾æ–‡å†™ä½œï¼š** æµ¦è¯­Â·çµç¬”2å¯ä»¥ç†è§£**è‡ªç”±å½¢å¼çš„å›¾æ–‡æŒ‡ä»¤è¾“å…¥ï¼ŒåŒ…æ‹¬å¤§çº²ã€æ–‡ç« ç»†èŠ‚è¦æ±‚ã€å‚è€ƒå›¾ç‰‡ç­‰**ï¼Œä¸ºç”¨æˆ·æ‰“é€ å›¾æ–‡å¹¶è²Œçš„ä¸“å±æ–‡ç« ã€‚ç”Ÿæˆçš„æ–‡ç« æ–‡é‡‡æ–ç„¶ï¼Œå›¾æ–‡ç›¸å¾—ç›Šå½°ï¼Œæä¾›æ²‰æµ¸å¼çš„é˜…è¯»ä½“éªŒã€‚

- **å‡†ç¡®çš„å›¾æ–‡é—®é¢˜è§£ç­”ï¼š** æµ¦è¯­Â·çµç¬”2å…·æœ‰æµ·é‡å›¾æ–‡çŸ¥è¯†ï¼Œå¯ä»¥å‡†ç¡®çš„å›å¤å„ç§å›¾æ–‡é—®ç­”éš¾é¢˜ï¼Œåœ¨è¯†åˆ«ã€æ„ŸçŸ¥ã€ç»†èŠ‚æè¿°ã€è§†è§‰æ¨ç†ç­‰èƒ½åŠ›ä¸Šè¡¨ç°æƒŠäººã€‚

- **æ°å‡ºæ€§èƒ½ï¼š** æµ¦è¯­Â·çµç¬”2åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­2-7Bæ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨13é¡¹å¤šæ¨¡æ€è¯„æµ‹ä¸­å¤§å¹…é¢†å…ˆåŒé‡çº§å¤šæ¨¡æ€æ¨¡å‹ï¼Œåœ¨å…¶ä¸­6é¡¹è¯„æµ‹ä¸­è¶…è¿‡ GPT-4V å’Œ Gemini Proã€‚

<p align="center">
    <img src="assets/benchmark.png" width="1000"/>
</p>

æˆ‘ä»¬å¼€æºçš„ æµ¦è¯­Â·çµç¬”2 åŒ…æ‹¬ä¸¤ä¸ªç‰ˆæœ¬:

- **InternLM-XComposer2-VL-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b"><img src="./assets/modelscope_logo.png" width="20px"> </a>ï¼ˆæµ¦è¯­Â·çµç¬”2-è§†è§‰é—®ç­”-7Bï¼‰: åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­2-7Bå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒï¼Œé¢å‘å¤šæ¨¡æ€è¯„æµ‹å’Œè§†è§‰é—®ç­”ã€‚æµ¦è¯­Â·çµç¬”2-è§†è§‰é—®ç­”-7Bæ˜¯ç›®å‰æœ€å¼ºçš„åŸºäº7Bé‡çº§è¯­è¨€æ¨¡å‹åŸºåº§çš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œé¢†è·‘å¤šè¾¾13ä¸ªå¤šæ¨¡æ€å¤§æ¨¡å‹æ¦œå•ã€‚

- **InternLM-XComposer2-7B** <a href="https://huggingface.co/internlm/internlm-xcomposer2-vl-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl2-7b"><img src="./assets/modelscope_logo.png" width="20px"> </a>: è¿›ä¸€æ­¥å¾®è°ƒï¼Œæ”¯æŒè‡ªç”±æŒ‡ä»¤è¾“å…¥å›¾æ–‡å†™ä½œçš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ã€‚
 
æ›´å¤šæ–¹æ³•ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š]()ï¼
  <br>

<!-- 
<p align="center">
    <figcaption align = "center"><b> InternLM-XComposer </b></figcaption>
<p> -->


<!-- ## Demo



https://github.com/InternLM/InternLM-XComposer/assets/22662425/0a2b475b-3f74-4f41-a5df-796680fa56cd
 -->





## æ›´æ–°æ¶ˆæ¯
* ```2023.01.26``` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer-VL-7B**çš„[è¯„æµ‹ä»£ç ](./evaluation/)å·²å¼€æºã€‚
* ```2023.01.26``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer2-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b) and [InternLM-XComposer-VL2-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b)å·²åœ¨**ModelScope**å¼€æºã€‚
* ```2023.01.26``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer2-7B](https://huggingface.co/internlm/internlm-xcomposer2-7b) and [InternLM-XComposer-VL2-7B](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b)å·²åœ¨**Hugging Face**å¼€æºã€‚
* ```2023.01.26``` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å…¬å¼€äº†InternLM-XComposer2æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š]()ã€‚
* ```2023.11.22``` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[ShareGPT4V](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V), ä¸€ä¸ªé«˜è´¨é‡çš„å¤§è§„æ¨¡å›¾æ–‡æè¿°æ•°æ®é›†ï¼Œä»¥åŠæ€§èƒ½ä¼˜ç§€çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ShareGPT4V-7Bã€‚
* ```2023.10.30``` ğŸ‰ğŸ‰ğŸ‰ çµç¬”åœ¨[Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards) å’Œ [Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation) å–å¾—äº†ç¬¬ä¸€åã€‚
* ```2023.10.19``` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒå¤šå¡æµ‹è¯•ï¼Œå¤šå¡Demo. ä¸¤å¼ 4090æ˜¾å¡å¯éƒ¨ç½²å…¨é‡Demoã€‚
* ```2023.10.12``` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒ4æ¯”ç‰¹é‡åŒ–Demoï¼Œ æ¨¡å‹æ–‡ä»¶å¯ä»[Hugging Face](https://huggingface.co/internlm/internlm-xcomposer-7b-4bit) and [ModelScope](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b-4bit) è·å–ã€‚
* ```2023.10.8``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b) å·²åœ¨Modelscopeå¼€æºã€‚
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer-VL-7B**çš„[è¯„æµ‹ä»£ç ](./evaluation/)å·²å¼€æºã€‚
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) å·²åœ¨Hugging Faceå¼€æºã€‚
* ```2023.9.27``` ğŸ‰ğŸ‰ğŸ‰ æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf)ã€‚
</br>


## è¯„æµ‹

æˆ‘ä»¬åœ¨13ä¸ªå¤šæ¨¡æ€è¯„æµ‹å¯¹InternLM-XComposer2-VLä¸Šè¿›è¡Œæµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š[MathVista](https://mathvista.github.io/), [MMMU](https://mmmu-benchmark.github.io/), [AI2D](https://prior.allenai.org/projects/diagram-understanding), [MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation), [MMBench](https://opencompass.org.cn/leaderboard-multimodal), [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal), [SEED-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard), [QBench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards), [HallusionBench](https://github.com/tianyi-lab/HallusionBench), [ChartQA](https://github.com/vis-nlp/ChartQA), [MM-Vet](https://github.com/yuweihao/MM-Vet), [LLaVA-in-the-wild](https://github.com/haotian-liu/LLaVA), [POPE](https://github.com/AoiDragon/POPE).


å¤ç°è¯„æµ‹ç»“æœï¼Œè¯·å‚è€ƒ[è¯„æµ‹ç»†èŠ‚](./evaluation/README.md)ã€‚

å¯¹æ¯”é—­æºå¤šæ¨¡æ€APIä»¥åŠå¼€æºSOTAæ¨¡å‹ã€‚
<p align="center">
    <img src="assets/table_closed.png" width="1200"/>
</p>

å¯¹æ¯”å¼€æºæ¨¡å‹ã€‚
<p align="center">
    <img src="assets/table_open.png" width="1200"/>
</p>


## ç¯å¢ƒè¦æ±‚

* python 3.8 and above
* pytorch 1.12 and above, 2.0 and above are recommended
* CUDA 11.4 and above are recommended (this is for GPU users)
  <br>

## å®‰è£…æ•™ç¨‹

åœ¨è¿è¡Œä»£ç ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§è¦æ±‚é…ç½®ç¯å¢ƒã€‚è¯·ç¡®è®¤ä½ çš„è®¾å¤‡ç¬¦åˆä»¥ä¸Šç¯å¢ƒéœ€æ±‚ï¼Œç„¶åå®‰è£…ç¯å¢ƒã€‚
è¯·å‚è€ƒ[å®‰è£…æ•™ç¨‹](docs/install_CN.md)

## å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•å®ç”¨çš„ ğŸ¤— Transformers ç‰ˆæœ¬ InternLM-XComposer çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚

<details>
  <summary>
    <b>ğŸ¤— Transformers</b>
  </summary>


```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer-7b', trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥-1955å¹´4æœˆ18æ—¥ï¼‰æ˜¯å¾·å›½å‡ºç”Ÿçš„ç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œ
# è¿™ä¸¤ä¸ªç†è®ºå¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚çˆ±å› æ–¯å¦è¿˜å‘ç°äº†å…‰ç”µæ•ˆåº”å®šå¾‹ï¼Œå¹¶å› æ­¤è·å¾—äº†1921å¹´çš„è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚
# çˆ±å› æ–¯å¦äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·ä¹Œå°”å§†å¸‚çš„ä¸€ä¸ªçŠ¹å¤ªäººå®¶åº­ã€‚ä»–åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦å’Œæ•°å­¦ï¼Œ # å¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œå…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå…‰ç”µæ•ˆåº”å®šå¾‹ã€‚
# 1915å¹´ï¼Œçˆ±å› æ–¯å¦å‘è¡¨äº†å¹¿ä¹‰ç›¸å¯¹è®ºï¼Œè¯¥ç†è®ºè§£é‡Šäº†å¼•åŠ›æ˜¯å¦‚ä½•é€šè¿‡æ—¶ç©ºå¼¯æ›²æ¥å½±å“ç‰©ä½“çš„è¿åŠ¨ã€‚è¿™ä¸€ç†è®ºæ”¹å˜äº†äººä»¬å¯¹å®‡å®™çš„è®¤è¯†ï¼Œå¹¶ä¸ºç°ä»£å®‡å®™å­¦å¥ å®šäº†åŸºç¡€ã€‚
# 1933å¹´ï¼Œçˆ±å› æ–¯å¦å› ä¸ºä»–çš„çŠ¹å¤ªè¡€ç»Ÿè€Œå—åˆ°çº³ç²¹å…šçš„è¿«å®³ï¼Œè¢«è¿«ç¦»å¼€å¾·å›½ã€‚ä»–æœ€ç»ˆå®šå±…åœ¨ç¾å›½ï¼Œå¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ä½™ç”Ÿã€‚1955å¹´4æœˆ18æ—¥ï¼Œçˆ±å› æ–¯å¦åœ¨æ™®æ—æ–¯é¡¿å»ä¸–ï¼Œäº«å¹´76å²ã€‚
# çˆ±å› æ–¯å¦çš„è´¡çŒ®å¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ï¼Œä»–è¢«è®¤ä¸ºæ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç§‘å­¦å®¶ä¹‹ä¸€ã€‚

# Single-Turn Text-Image Dialogue
text = 'è¯·é—®è¿™å¼ å›¾ç‰‡é‡Œé¢çš„äººæ˜¯è°ï¼Ÿå¹¶ä»‹ç»ä¸‹ä»–ã€‚'
image = 'examples/images/aiyinsitan.jpg'
response = model.generate(text, image)
print(response)
# å›¾ç‰‡é‡Œçš„äººæ˜¯é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼‰ï¼Œä¸€ä½è‘—åçš„ç‰©ç†å­¦å®¶å’Œç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·çš„ä¹Œå°”å§†å¸‚ï¼Œ
# å¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ ç«¥å¹´å’Œå°‘å¹´æ—¶ä»£ã€‚çˆ±å› æ–¯å¦åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦ï¼Œå¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œ
# å…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œè´¨èƒ½æ–¹ç¨‹E=mc^2ã€‚1921å¹´ï¼Œçˆ±å› æ–¯å¦è·å¾—äº†è¯ºè´å°”ç‰©ç†å­¦å¥–ï¼Œä»¥è¡¨å½°ä»–å¯¹å…‰ç”µæ•ˆåº”çš„å‘ç°å’Œå¯¹ç‹­ä¹‰ç›¸å¯¹è®ºçš„è´¡çŒ®ã€‚

# Multi-Turn Text-Image Dialogue
# 1st turn
text = 'å›¾ç‰‡é‡Œé¢çš„æ˜¯è°ï¼Ÿ'
response, history = model.chat(text=text, image=image, history=None)
print(response)
# å›¾ç‰‡é‡Œé¢çš„äººç‰©æ˜¯é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼‰ï¼Œä¸€ä½è‘—åçš„ç‰©ç†å­¦å®¶å’Œç†è®ºç‰©ç†å­¦å®¶ã€‚

# 2nd turn
text = 'ä»–æœ‰å“ªäº›æˆå°±?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ï¼Œä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œä¸ºç°ä»£ç‰©ç†å­¦çš„å‘å±•åšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ã€‚
# æ­¤å¤–ï¼Œä»–è¿˜æå‡ºäº†å…‰é‡å­ç†è®ºã€è´¨èƒ½å…³ç³»ç­‰é‡è¦ç†è®ºï¼Œå¯¹ç°ä»£ç‰©ç†å­¦çš„å‘å±•äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚

# 3rd turn
text = 'ä»–æ˜¯æœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶å—?'
response, history = model.chat(text=text, image=None, history=history)
print(response)
# æ˜¯çš„ï¼Œé˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦æ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç‰©ç†å­¦å®¶ä¹‹ä¸€ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œä¸ºç°ä»£ç‰©ç†å­¦çš„å‘å±•åšå‡ºäº†å·¨å¤§çš„è´¡çŒ®ã€‚
```
</details>


<details>
  <summary>
    <b>ğŸ¤– ModelScope</b>
  </summary>


```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-xcomposer-7b')
model = AutoModel.from_pretrained(model_dir, trust_remote_code=True).cuda().eval()
tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)
model.tokenizer = tokenizer

# example image
image = 'examples/images/aiyinsitan.jpg'

# Single-Turn Pure-Text Dialogue
text = 'è¯·ä»‹ç»ä¸‹çˆ±å› æ–¯å¦çš„ç”Ÿå¹³'
response = model.generate(text)
print(response)
# é˜¿å°”ä¼¯ç‰¹Â·çˆ±å› æ–¯å¦ï¼ˆAlbert Einsteinï¼Œ1879å¹´3æœˆ14æ—¥-1955å¹´4æœˆ18æ—¥ï¼‰æ˜¯å¾·å›½å‡ºç”Ÿçš„ç†è®ºç‰©ç†å­¦å®¶ã€‚ä»–æå‡ºäº†ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå¹¿ä¹‰ç›¸å¯¹è®ºï¼Œ
# è¿™ä¸¤ä¸ªç†è®ºå¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚çˆ±å› æ–¯å¦è¿˜å‘ç°äº†å…‰ç”µæ•ˆåº”å®šå¾‹ï¼Œå¹¶å› æ­¤è·å¾—äº†1921å¹´çš„è¯ºè´å°”ç‰©ç†å­¦å¥–ã€‚
# çˆ±å› æ–¯å¦äº1879å¹´3æœˆ14æ—¥å‡ºç”Ÿäºå¾·å›½å·´ç™»-ç¬¦è…¾å ¡å·ä¹Œå°”å§†å¸‚çš„ä¸€ä¸ªçŠ¹å¤ªäººå®¶åº­ã€‚ä»–åœ¨ç‘å£«è‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢å­¦ä¹ ç‰©ç†å­¦å’Œæ•°å­¦ï¼Œ # å¹¶äº1905å¹´å‘è¡¨äº†ä¸€ç³»åˆ—é‡è¦è®ºæ–‡ï¼Œå…¶ä¸­åŒ…æ‹¬ç‹­ä¹‰ç›¸å¯¹è®ºå’Œå…‰ç”µæ•ˆåº”å®šå¾‹ã€‚
# 1915å¹´ï¼Œçˆ±å› æ–¯å¦å‘è¡¨äº†å¹¿ä¹‰ç›¸å¯¹è®ºï¼Œè¯¥ç†è®ºè§£é‡Šäº†å¼•åŠ›æ˜¯å¦‚ä½•é€šè¿‡æ—¶ç©ºå¼¯æ›²æ¥å½±å“ç‰©ä½“çš„è¿åŠ¨ã€‚è¿™ä¸€ç†è®ºæ”¹å˜äº†äººä»¬å¯¹å®‡å®™çš„è®¤è¯†ï¼Œå¹¶ä¸ºç°ä»£å®‡å®™å­¦å¥ å®šäº†åŸºç¡€ã€‚
# 1933å¹´ï¼Œçˆ±å› æ–¯å¦å› ä¸ºä»–çš„çŠ¹å¤ªè¡€ç»Ÿè€Œå—åˆ°çº³ç²¹å…šçš„è¿«å®³ï¼Œè¢«è¿«ç¦»å¼€å¾·å›½ã€‚ä»–æœ€ç»ˆå®šå±…åœ¨ç¾å›½ï¼Œå¹¶åœ¨é‚£é‡Œåº¦è¿‡äº†ä»–çš„ä½™ç”Ÿã€‚1955å¹´4æœˆ18æ—¥ï¼Œçˆ±å› æ–¯å¦åœ¨æ™®æ—æ–¯é¡¿å»ä¸–ï¼Œäº«å¹´76å²ã€‚
# çˆ±å› æ–¯å¦çš„è´¡çŒ®å¯¹ç°ä»£ç‰©ç†å­¦äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ï¼Œä»–è¢«è®¤ä¸ºæ˜¯20ä¸–çºªæœ€ä¼Ÿå¤§çš„ç§‘å­¦å®¶ä¹‹ä¸€ã€‚
```
</details>


## Web UI

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªè½»æ¾æ­å»º Web UI demo çš„ä»£ç .

<p align="center">
    <img src="demo_asset/assets/UI_en.png" width="800"/>
</p>


è¯·è¿è¡Œä»¥ä¸‹ä»£ç ï¼ˆéœ€è¦>=32GBæ˜¾å­˜çš„GPU, æ¨èï¼‰

```
python examples/web_demo.py
```
æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ Web UI [ç”¨æˆ·æŒ‡å—](demo_asset/demo.md)ã€‚ å¦‚æœæ‚¨æƒ³è¦æ›´æ”¹æ¨¡å‹å­˜æ”¾çš„æ–‡ä»¶å¤¹ï¼Œè¯·ä½¿ç”¨ --folder=new_folder é€‰é¡¹ã€‚

## é‡åŒ–
æˆ‘ä»¬æä¾›4bité‡åŒ–æ¨¡å‹æ¥ç¼“è§£æ¨¡å‹çš„å†…å­˜éœ€æ±‚ã€‚ è¦è¿è¡Œ4bitæ¨¡å‹ï¼ˆGPUå†…å­˜> = 12GBï¼‰ï¼Œæ‚¨éœ€è¦é¦–å…ˆå®‰è£…ç›¸åº”çš„[ä¾èµ–åŒ…](docs/install_CN.md)ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡ŒèŠå¤©å’Œç½‘é¡µæ¼”ç¤ºï¼š
```
# 4-bit chat
python examples/example_chat_4bit.py
# 4-bit web demo
python examples/web_demo_4bit.py
```

## å¤šGPUæµ‹è¯•
å¦‚æœä½ æœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: pip install accelerateï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡ŒèŠå¤©å’Œç½‘é¡µæ¼”ç¤ºï¼š
```
# chat with 2 GPUs
python examples/example_chat.py --num_gpus 2
# web demo with 2 GPUs
python examples/web_demo.py --num_gpus 2
```
<br>

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä¸€ä¸ª star :star: å’Œ å¼•ç”¨ :pencil: :)

```BibTeX
@misc{zhang2023internlmxcomposer,
      title={InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition}, 
      author={Pan Zhang and Xiaoyi Dong and Bin Wang and Yuhang Cao and Chao Xu and Linke Ouyang and Zhiyuan Zhao and Shuangrui Ding and Songyang Zhang and Haodong Duan and Hang Yan and Xinyue Zhang and Wei Li and Jingwen Li and Kai Chen and Conghui He and Xingcheng Zhang and Yu Qiao and Dahua Lin and Jiaqi Wang},
      year={2023},
      eprint={2309.15112},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

<br>

## è®¸å¯è¯ & è”ç³»æˆ‘ä»¬

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚
