<p align="center">
    <img src="./assets/logo_cn.png" width="400"/>
</p>
<p align="center">
    <b><font size="6">æµ¦è¯­Â·çµç¬”2.5</font></b>
</p>

<!-- <div align="center">
        InternLM-XComposer <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp ï½œ InternLM-VL <a href="">ğŸ¤– <a> <a href="">ğŸ¤—</a>&nbsp | Technical Report <a href=""> <a> ğŸ“„  -->

<div align="center">
        InternLM-XComposer2.5 <a href="https://huggingface.co/internlm/internlm-xcomposer2d5-7b">ğŸ¤—</a> <a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2d5-7b"><img src="./assets/modelscope_logo.png" width="20px"></a> &nbspï½œ æµ¦è¯­Â·çµç¬”2.5æŠ€æœ¯æŠ¥å‘Š <a href="https://arxiv.org/abs/">  ğŸ“„ </a>  

[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_CN.md)

<p align="center">
    æ„Ÿè°¢ç¤¾åŒºæä¾›çš„ InternLM-XComposer2 <a href="https://huggingface.co/spaces/Willow123/InternLM-XComposer">Hugging Face åœ¨çº¿è¯•ç”¨</a> | <a href="https://openxlab.org.cn/apps/detail/WillowBreeze/InternLM-XComposer">OpenXLab åœ¨çº¿è¯•ç”¨</a>
</p>

</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> å’Œ <a href="https://r.vansin.top/?r=internwx" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>
</p>

<br>

## æœ¬ä»“åº“åŒ…æ‹¬çš„å¤šæ¨¡æ€é¡¹ç›®
> [**InternLM-XComposer2.5**](https://github.com/InternLM/InternLM-XComposer): **A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output**

> [**InternLM-XComposer2-<img src="./assets/4k.png" width="25px">**](https://github.com/InternLM/InternLM-XComposer): **A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD**

> [**InternLM-XComposer2**](https://github.com/InternLM/InternLM-XComposer): **Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Models**

> [**InternLM-XComposer**](https://github.com/InternLM/InternLM-XComposer/tree/main/InternLM-XComposer-1.0): **A Vision-Language Large Model for Advanced Text-image Comprehension and Composition**

> <img src="https://raw.githubusercontent.com/ShareGPT4V/ShareGPT4V-Resources/master/images/logo_tight.png" style="vertical-align: -20px;" :height="25px" width="25px">[**ShareGPT4V**](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V): **Improving Large Multi-modal Models with Better Captions**
 
> [**DualFocus**](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/DualFocus): **Integrating Macro and Micro Perspectives in Multi-modal Large Language Models**


</br>

**æµ¦è¯­Â·çµç¬”2.5**æ˜¯åŸºäº[ä¹¦ç”ŸÂ·æµ¦è¯­2](https://github.com/InternLM/InternLM/tree/main)å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„çªç ´æ€§çš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œä»…ä½¿ç”¨ 7B LLM åç«¯å°±è¾¾åˆ°äº† GPT-4V çº§åˆ«çš„èƒ½åŠ›ã€‚æµ¦è¯­Â·çµç¬”2.5ä½¿ç”¨24Käº¤é”™çš„å›¾åƒ-æ–‡æœ¬ä¸Šä¸‹æ–‡è¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡RoPEå¤–æ¨å¯ä»¥æ— ç¼æ‰©å±•åˆ°96Ké•¿çš„ä¸Šä¸‹æ–‡ã€‚è¿™ç§é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ä½¿æµ¦è¯­Â·çµç¬”2.5åœ¨éœ€è¦å¹¿æ³›è¾“å…¥å’Œè¾“å‡ºä¸Šä¸‹æ–‡çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

- **è¶…é«˜åˆ†è¾¨ç‡ç†è§£**ï¼šæµ¦è¯­Â·çµç¬”2.5ä½¿ç”¨560Ã—560åˆ†è¾¨ç‡çš„ViTè§†è§‰ç¼–ç å™¨å¢å¼ºäº†IXC2-4KHDä¸­æå‡ºçš„åŠ¨æ€åˆ†è¾¨ç‡è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå…·æœ‰ä»»æ„çºµæ¨ªæ¯”çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚
- **ç»†ç²’åº¦è§†é¢‘ç†è§£**ï¼šæµ¦è¯­Â·çµç¬”2.5å°†è§†é¢‘è§†ä¸ºç”±æ•°ååˆ°æ•°åƒå¸§ç»„æˆçš„è¶…é«˜åˆ†è¾¨ç‡å¤åˆå›¾åƒï¼Œä»è€Œé€šè¿‡å¯†é›†é‡‡æ ·å’Œæ¯å¸§æ›´é«˜çš„åˆ†è¾¨ç‡æ•æ‰ç»†èŠ‚ã€‚
- **å¤šè½®å¤šå›¾åƒå¯¹è¯**ï¼šæµ¦è¯­Â·çµç¬”2.5æ”¯æŒè‡ªç”±å½¢å¼çš„å¤šè½®å¤šå›¾åƒå¯¹è¯ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šè½®å¯¹è¯ä¸­ä¸äººç±»è‡ªç„¶äº’åŠ¨ã€‚
- **ç½‘é¡µåˆ¶ä½œ**ï¼šæµ¦è¯­Â·çµç¬”2.5å¯ä»¥é€šè¿‡éµå¾ªæ–‡æœ¬-å›¾åƒæŒ‡ä»¤æ¥åˆ›å»ºç½‘é¡µï¼ŒåŒ…æ‹¬æºä»£ç ï¼ˆHTMLã€CSSå’ŒJavaScriptï¼‰çš„ç»„åˆã€‚
- **é«˜è´¨é‡æ–‡æœ¬-å›¾åƒæ–‡ç« åˆ›ä½œ**ï¼šæµ¦è¯­Â·çµç¬”2.5åˆ©ç”¨ç‰¹åˆ«è®¾è®¡çš„â€œæ€ç»´é“¾â€ï¼ˆCoTï¼‰å’Œâ€œç›´æ¥åå¥½ä¼˜åŒ–â€ï¼ˆDPOï¼‰æŠ€æœ¯ï¼Œæ˜¾è‘—æé«˜äº†å…¶åˆ›ä½œå†…å®¹çš„è´¨é‡ã€‚
- **å‡ºè‰²çš„æ€§èƒ½**ï¼šæµ¦è¯­Â·çµç¬”2.5åœ¨28ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨16ä¸ªåŸºå‡†æµ‹è¯•ä¸Šä¼˜äºç°æœ‰çš„å¼€æºå…ˆè¿›æ¨¡å‹ã€‚å®ƒè¿˜åœ¨16ä¸ªå…³é”®ä»»åŠ¡ä¸Šè¶…è¶Šæˆ–ä¸GPT-4Vå’ŒGemini Proè¡¨ç°ç›¸è¿‘ã€‚

<p align="center">
    <img src="assets/Benchmark_radar.png" width="1000"/>
</p>
  


æ›´å¤šæ–¹æ³•ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2401.16420)ï¼
<br>

<!--
<p align="center">
    <figcaption align = "center"><b> InternLM-XComposer </b></figcaption>
<p> -->

<!-- ## Demo


https://github.com/InternLM/InternLM-XComposer/assets/22662425/0a2b475b-3f74-4f41-a5df-796680fa56cd
 -->

## Demo Video

[![Watch the video](https://img.youtube.com/vi/8tYpiQNOJww/maxresdefault.jpg)](https://youtu.be/8tYpiQNOJww)

## æ›´æ–°æ¶ˆæ¯
- `2024.07.03` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[InternLM-XComposer2.5-7B](https://huggingface.co/internlm/internlm-xcomposer2d5-7b).
- `2024.04.09` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[InternLM-XComposer2-4KHD-7B](https://huggingface.co/internlm/internlm-xcomposer2-4khd-7b) å’Œ [è¯„æµ‹ä»£ç ](./evaluation/README.md).
- `2024.04.09` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[InternLM-XComposer2-VL-1.8B](https://huggingface.co/internlm/internlm-xcomposer2-4khd-7b).
- `2024.02.22` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[DualFocus](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/DualFocus), ä¸€ä¸ªæ•´åˆå®è§‚å’Œå¾®è§‚è§†è§’äºå¤šè¯­è¨€å¤§æ¨¡å‹ä¸­ä»¥æå‡è§†è§‰-è¯­è¨€ä»»åŠ¡æ€§èƒ½çš„æ¡†æ¶ã€‚
* ```2024.02.06``` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer2-7B-4bit](https://huggingface.co/internlm/internlm-xcomposer2-7b-4bit) å’Œ [InternLM-XComposer-VL2-7B-4bit](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b-4bit) å·²åœ¨**Hugging Face**å’Œ**ModelScope**å¼€æºã€‚
- `2024.02.02` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer2-VL-7B**çš„[å¾®è°ƒä»£ç ](./finetune/)å·²å¼€æºã€‚
- `2024.01.26` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer2-VL-7B**çš„[è¯„æµ‹ä»£ç ](./evaluation/README.md)å·²å¼€æºã€‚
- `2024.01.26` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer2-7B](https://huggingface.co/internlm/internlm-xcomposer2-7b) å’Œ [InternLM-XComposer-VL2-7B](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b)å·²åœ¨**Hugging Face**å’Œ**ModelScope**å¼€æºã€‚
- `2024.01.26` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å…¬å¼€äº†InternLM-XComposer2æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2401.16420)ã€‚
- `2023.11.22` ğŸ‰ğŸ‰ğŸ‰ æˆ‘ä»¬å¼€æºäº†[ShareGPT4V](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V), ä¸€ä¸ªé«˜è´¨é‡çš„å¤§è§„æ¨¡å›¾æ–‡æè¿°æ•°æ®é›†ï¼Œä»¥åŠæ€§èƒ½ä¼˜ç§€çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ShareGPT4V-7Bã€‚
- `2023.10.30` ğŸ‰ğŸ‰ğŸ‰ çµç¬”åœ¨[Q-Bench](https://github.com/Q-Future/Q-Bench/tree/master/leaderboards#overall-leaderboards) å’Œ [Tiny LVLM](https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation) å–å¾—äº†ç¬¬ä¸€åã€‚
- `2023.10.19` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒå¤šå¡æµ‹è¯•ï¼Œå¤šå¡Demo. ä¸¤å¼ 4090æ˜¾å¡å¯éƒ¨ç½²å…¨é‡Demoã€‚
- `2023.10.12` ğŸ‰ğŸ‰ğŸ‰ æ”¯æŒ4æ¯”ç‰¹é‡åŒ–Demoï¼Œ æ¨¡å‹æ–‡ä»¶å¯ä»[Hugging Face](https://huggingface.co/internlm/internlm-xcomposer-7b-4bit) å’Œ [ModelScope](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b-4bit) è·å–ã€‚
- `2023.10.8` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b) å·²åœ¨Modelscopeå¼€æºã€‚
- `2023.9.27` ğŸ‰ğŸ‰ğŸ‰ **InternLM-XComposer-VL-7B**çš„[è¯„æµ‹ä»£ç ](./InternLM-XComposer-1.0/evaluation/)å·²å¼€æºã€‚
- `2023.9.27` ğŸ‰ğŸ‰ğŸ‰ [InternLM-XComposer-7B](https://huggingface.co/internlm/internlm-xcomposer-7b) å’Œ [InternLM-XComposer-VL-7B](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) å·²åœ¨Hugging Faceå¼€æºã€‚
- `2023.9.27` ğŸ‰ğŸ‰ğŸ‰ æ›´å¤šæŠ€æœ¯ç»†èŠ‚è¯·å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/pdf/2309.15112.pdf)ã€‚
  </br>

## æ¨¡å‹åˆé›†

| æ¨¡å‹                        | ç”¨é€”                | Transformers(HF)                                                                           | ModelScope(HF)                                                                                                                                                               | å¼€æºæ—¥æœŸ   |
| --------------------------- | ------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| **InternLM-XComposer2.5**    | è§†é¢‘ç†è§£ï¼Œå¤šå›¾å¤šè½®å¯¹è¯ï¼Œè¶…é«˜åˆ†è¾¨ç‡å›¾åƒç†è§£ï¼Œç½‘é¡µåˆ›ä½œï¼Œæ–‡ç« åˆ›ä½œï¼Œ Benchmark | [ğŸ¤—internlm-xcomposer2.5](https://huggingface.co/internlm/internlm-xcomposer2d5-7b)       | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2.5](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2d5-7b/summary)       | 2024-07-03   |
| **InternLM-XComposer2-4KHD**     | 4Kåˆ†è¾¨ç‡å›¾åƒç†è§£, Benchmark, è§†è§‰é—®ç­”          | [ğŸ¤—internlm-xcomposer2-4khd-7b](https://huggingface.co/internlm/internlm-xcomposer2-4khd-7b)         | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-4khd-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-4khd-7b/summary)         | 2024-04-09   |
| **InternLM-XComposer2-VL-1.8B**  | Benchmark, è§†è§‰é—®ç­”             | [ğŸ¤—internlm-xcomposer2-vl-1_8b](https://huggingface.co/internlm/internlm-xcomposer2-vl-1_8b)   | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-vl-1_8b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-1_8b/summary)   | 2024-04-09   |
| **InternLM-XComposer2**     | å›¾æ–‡åˆ›ä½œ            | [ğŸ¤—internlm-xcomposer2-7b](https://huggingface.co/internlm/internlm-xcomposer2-7b)         | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b/summary)         | 2024-01-26 |
| **InternLM-XComposer2-VL**  | Benchmark, è§†è§‰é—®ç­” | [ğŸ¤—internlm-xcomposer2-vl-7b](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b)   | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-vl-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b/summary)   | 2024-01-26 |
| **InternLM-XComposer2-4bit**  |  å›¾æ–‡åˆ›ä½œ   | [ğŸ¤—internlm-xcomposer2-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer2-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b-4bit/summary) |  2024-02-06   |
| **InternLM-XComposer2-VL-4bit**   | Benchmark, è§†è§‰é—®ç­”   | [ğŸ¤—internlm-xcomposer2-vl-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-vl-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b-4bit/summary) |  2024-02-06   |
| **InternLM-XComposer**      | å›¾æ–‡åˆ›ä½œ, è§†è§‰é—®ç­”  | [ğŸ¤—internlm-xcomposer-7b](https://huggingface.co/internlm/internlm-xcomposer-7b)           | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b/summary)           | 2023-09-26 |
| **InternLM-XComposer-4bit** | å›¾æ–‡åˆ›ä½œ, è§†è§‰é—®ç­”  | [ğŸ¤—internlm-xcomposer-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b-4bit/summary) | 2023-09-26 |
| **InternLM-XComposer-VL**   | Benchmark           | [ğŸ¤—internlm-xcomposer-vl-7b](https://huggingface.co/internlm/internlm-xcomposer-vl-7b)     | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-vl-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b/summary)     | 2023-09-26 |

## è¯„æµ‹

æˆ‘ä»¬åœ¨28ä¸ªå¤šæ¨¡æ€è¯„æµ‹å¯¹InternLM-XComposer2-VLä¸Šè¿›è¡Œæµ‹è¯•ï¼ŒåŒ…æ‹¬å›¾åƒè¯„æµ‹ [MMDU](https://github.com/Liuziyu77/MMDU), [MMStar](https://github.com/MMStar-Benchmark/MMStar), [RealWorldQA](https://x.ai/blog/grok-1.5v),  [Design2Code](https://salt-nlp.github.io/Design2Code/), [DocVQA](https://rrc.cvc.uab.es/?ch=17), [Infographics VQA](https://rrc.cvc.uab.es/?ch=17), [TextVQA](https://textvqa.org/), [ChartQA](https://github.com/vis-nlp/ChartQA), [OCRBench](https://github.com/Yuliang-Liu/MultimodalOCR), [DeepFrom](https://wandb.ai/stacey/deepform_v1/reports/DeepForm-Understand-Structured-Documents-at-Scale--VmlldzoyODQ3Njg), [WTQ](https://arxiv.org/abs/1508.00305), [VisualMRC](https://github.com/nttmdlab-nlp/VisualMRC), [TabFact](https://tabfact.github.io/), [MathVista](https://mathvista.github.io/), [MMMU](https://mmmu-benchmark.github.io/), [AI2D](https://prior.allenai.org/projects/diagram-understanding), [MME](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation), [MMBench](https://opencompass.org.cn/leaderboard-multimodal), [MMBench-CN](https://opencompass.org.cn/leaderboard-multimodal), [SEED-Bench](https://huggingface.co/spaces/AILab-CVC/SEED-Bench_Leaderboard), [HallusionBench](https://github.com/tianyi-lab/HallusionBench), [MM-Vet](https://github.com/yuweihao/MM-Vet), å’Œè§†é¢‘è¯„æµ‹ [MVBench](https://github.com/OpenGVLab/Ask-Anything), [MLVU](https://github.com/FlagOpen/FlagEmbedding/tree/master/MLVU/evaluation), [Video-MME](https://github.com/BradyFU/Video-MME), [MMBench-Video](https://github.com/open-compass/VLMEvalKit), [TempCompass](https://github.com/llyx97/TempCompass)

å¤ç°è¯„æµ‹ç»“æœï¼Œè¯·å‚è€ƒ[è¯„æµ‹ç»†èŠ‚](./evaluation/README.md)ã€‚

### åœ¨è§†é¢‘å’Œé«˜åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šä¸é—­æºå¤šæ¨¡æ€APIä»¥åŠå¼€æºSOTAæ¨¡å‹å¯¹æ¯”ç»“æœã€‚

|            | MVBench    | MLVU        | MME-Video | MMBench-Video | TempCompass | DocVQA      | ChartVQA    | InfoVQA     | TextVQA     | OCRBench | DeepForm   | WTQ        | VisualMRC  | TabFact     |
|------------|------------|-------------|-----------|---------------|-------------|-------------|-------------|-------------|-------------|----------|------------|------------|------------|-------------|
|            | VideoChat2 | InternVL1.5 | LIVA      | InternVL1.5   | Qwen-VL     | InternVL1.5 | InternVL1.5 | InternVL1.5 | InternVL1.5 | GLM-4v   | DocOwl 1.5 | DocOwl 1.5 | DocOwl 1.5 | DocOwl 1.5  |
|            | 7B         | 26B         | 34B       | 26B           | 7B          | 26B         | 26B         | 26B         | 26B         | 9B       | 8B         | 8B         | 8B         | 8B          |
|            | 60.4       | 50.4        | 59.0      | 42.0          | 58.4        | 90.9        | 83.8        | 72.5        | 80.6        | 77.6     | 68.8       | 40.6       | 246.4      | 80.2        |
|            |            |             |           |               |             |             |             |             |             |          |            |            |            |             |
| GPT-4V     | 43.5       | 49.2        | 59.9      | 56.0          | ---         | 88.4        | 78.5        | 75.1        | 78.0        | 51.6     | ---        | ---        | ---        | ---         |
| Gemini-Pro | ---        | ---         | 75.0      | 49.3          | 70.6        | 88.1        | 74.1        | 75.2        | 74.6        | 68.0     | ---        | ---        | ---        | ---         |
| Ours       | 69.1       | 58.8        | 55.8      | 46.9          | 67.1        | 90.9        | 82.2        | 69.9        | 78.2        | 69.0     | 71.2       | 53.6       | 307.5      | 85.2        |




### åœ¨å¤šå›¾å¯¹è¯å’Œé€šç”¨VQAä»»åŠ¡ä¸Šä¸é—­æºå¤šæ¨¡æ€APIä»¥åŠå¼€æºSOTAæ¨¡å‹å¯¹æ¯”ç»“æœã€‚

|            | MMStar      | MMDU       | Design2Code      | RealWQA | MathVista | AI2D         | MMMU  | MME          | MMB          | MMB-CN       | MMB-1.1      | SEEDI | MM-Vet |
|------------|-------------|------------------|---------|-----------|--------------|-------|--------------|--------------|--------------|--------------|-------|--------|--------|
|            | InternVL1.5 | LLaVa1.6-mistral |Design2Code | WeMM    | WeMM      | InternVL-1.5 | 360VL | InternVL-1.5 | InternVL-1.5 | InternVL-1.5 | InternVL-1.5 | WeMM  | GLM-4v |
|            | 26B         | 8B               |   18B |  8B      | 8B        | 26B          | 70B   | 26B          | 26B          | 26B          | 26B          | 8B    | 14B    |
|        | 57.1        | 42.8      | 80.4       | 68.1    | 54.9      | 80.6         | 53.4  | 2,189.6      | 82.3         | 80.7         | 79.7         | 75.9  | 58.0   |
|            |             |                  |         |           |              |       |              |              |              |              |       |        |
| GPT-4V     | 57.1        | 66.3       |  84.8 | 68.0    | 47.8      | 75.5         | 56.8  | 1,926.5      | 81.3         | 80.2         | 79.8         | 69.1  | 56.8   |
| Gemini-Pro | 42.6        | ---       |  79.4  | 64.1    | 45.8      | 70.2         | 47.9  | 1,933.3      | 73.9         | 74.3         | 73.9         | 70.7  | 59.2   |
| Ours       | 59.9        |   56.6     |  85.1  | 67.8    | 63.8      | 81.5         | 42.9  | 2,229.0      | 82.2         | 80.8         | 79.4         | 75.4  | 51.7   |


## ç¯å¢ƒè¦æ±‚

- python 3.8 and above
- pytorch 1.12 and above, 2.0 and above are recommended
- CUDA 11.4 and above are recommended (this is for GPU users)
- [flash-attention2](https://github.com/Dao-AILab/flash-attention) is required for the 4KHD model.
  <br>

## å®‰è£…æ•™ç¨‹

åœ¨è¿è¡Œä»£ç ä¹‹å‰ï¼Œè¯·å…ˆæŒ‰ç…§è¦æ±‚é…ç½®ç¯å¢ƒã€‚è¯·ç¡®è®¤ä½ çš„è®¾å¤‡ç¬¦åˆä»¥ä¸Šç¯å¢ƒéœ€æ±‚ï¼Œç„¶åå®‰è£…ç¯å¢ƒã€‚
è¯·å‚è€ƒ[å®‰è£…æ•™ç¨‹](docs/install_CN.md)

## å¿«é€Ÿå¼€å§‹

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•å®ç”¨çš„ ğŸ¤— Transformers ç‰ˆæœ¬ InternLM-XComposerç³»åˆ—çš„ä½¿ç”¨æ¡ˆä¾‹ã€‚ 


<details>
  <summary>
    <b>è§†é¢‘ç†è§£</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'Here are some frames of a video. Describe this video in detail'
image = ['./examples/liuxiang.mp4',]
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response, his = model.chat(tokenizer, query, image, do_sample=False, num_beams=3, use_meta=True)
print(response)
#The video opens with a shot of an athlete, dressed in a red and yellow uniform with the word "CHINA" emblazoned across the front, preparing for a race. 
#The athlete, Liu Xiang, is seen in a crouched position, focused and ready, with the Olympic rings visible in the background, indicating the prestigious setting of the Olympic Games. As the race commences, the athletes are seen sprinting towards the hurdles, their determination evident in their powerful strides. 
#The camera captures the intensity of the competition, with the athletes' numbers and times displayed on the screen, providing a real-time update on their performance. The race reaches a climax as Liu Xiang, still in his red and yellow uniform, triumphantly crosses the finish line, his arms raised in victory. 
#The crowd in the stands erupts into cheers, their excitement palpable as they witness the athlete's success. The video concludes with a close-up shot of Liu Xiang, still basking in the glory of his victory, as the Olympic rings continue to symbolize the significance of the event.

query = 'tell me the athlete code of Liu Xiang'
image = ['./examples/liuxiang.mp4',]
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response, _ = model.chat(tokenizer, query, image, history=his, do_sample=False, num_beams=3, use_meta=True)
print(response)
#The athlete code of Liu Xiang, as displayed on his uniform in the video, is "1363".
```

</details>

<details>
  <summary>
    <b>å¤šå›¾å¤šè½®å¯¹è¯</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'Image1 <ImageHere>; Image2 <ImageHere>; Image3 <ImageHere>; I want to buy a car from the three given cars, analyze their advantages and weaknesses one by one'
image = ['./examples/cars1.jpg',
        './examples/cars2.jpg',
        './examples/cars3.jpg',]
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response, his = model.chat(tokenizer, query, image, do_sample=False, num_beams=3, use_meta=True)
print(response)
#To analyze the advantages and disadvantages of each car, we need to consider factors such as brand reputation, performance, design, cost, and maintenance. 
#1. Mercedes-Benz: - Advantages: Known for its luxury and reliability, the Mercedes-Benz brand offers a high level of comfort, advanced technology, and superior craftsmanship. The vehicle in the image appears to be an SUV, which is versatile for both city driving and off-road conditions. - Disadvantages: Typically, Mercedes-Benz vehicles are more expensive compared to other brands, and they may require more frequent maintenance due to their luxury status. 
#2. Bugatti: - Advantages: Bugatti is renowned for producing some of the fastest and most powerful cars in the world. The vehicle in the image is a sports car, likely offering an exhilarating driving experience with its high-performance engine and advanced aerodynamics. - Disadvantages: Bugatti cars are extremely expensive, making them less accessible to the average consumer. They also require specialized knowledge for maintenance and may not be suitable for everyday driving due to their high-performance nature. 
#3. BMW: - Advantages: BMW is a well-respected manufacturer known for its innovative engineering and design. The car in the image appears to be an electric vehicle (EV), which offers advantages such as lower emissions, reduced noise pollution, and potentially lower operating costs. - Disadvantages: EVs like the one in the image may have a shorter range compared to traditional gasoline-powered vehicles, limiting their suitability for long-distance travel. 
#Additionally, the initial cost of purchasing an EV can be higher than that of a conventional car. In conclusion, each car has its own set of advantages and disadvantages. The Mercedes-Benz offers luxury and versatility, the Bugatti provides high performance and exclusivity, and the BMW represents innovation in electric vehicle technology. The choice ultimately depends on the buyer's priorities, such as comfort, performance, environmental impact, and budget.

query = 'Image4 <ImageHere>; How about the car in Image4'
image.append('./examples/cars4.jpg')        
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response, _ = model.chat(tokenizer, query, image, do_sample=False, num_beams=3, history= his, use_meta=True)
print(response)
#The car in Image4 is a red sports car, which appears to be a Ferrari. Ferrari is a renowned Italian manufacturer known for producing some of the most iconic and high-performance sports cars in the world. - Advantages: Ferrari vehicles are synonymous with speed, luxury, and engineering excellence. 
#The car in the image likely offers an exhilarating driving experience with its powerful engine, advanced aerodynamics, and high-quality craftsmanship. The red color adds to the car's aesthetic appeal, making it stand out on the road. - Disadvantages: Ferrari cars are extremely expensive, making them less accessible to the average consumer. 
#They also require specialized knowledge for maintenance and may not be suitable for everyday driving due to their high-performance nature. In conclusion, the Ferrari in Image4 represents a pinnacle of automotive engineering and design, offering unmatched performance and luxury. 
#However, its high cost and specialized maintenance requirements make it less practical for everyday use compared to the other vehicles in the images.
```


</details>

<details>
  <summary>
    <b>é«˜åˆ†è¾¨ç‡å›¾åƒç†è§£</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'Analyze the given image in a detail manner'
image = ['./examples/dubai.png']
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response, _ = model.chat(tokenizer, query, image, do_sample=False, num_beams=3, use_meta=True)
print(response)
#The infographic is a visual representation of various facts about Dubai. It begins with a statement about Palm Jumeirah, highlighting it as the largest artificial island visible from space. It then provides a historical context, noting that in 1968, there were only a few cars in Dubai, contrasting this with the current figure of more than 1.5 million vehicles. 
#The infographic also points out that Dubai has the world's largest Gold Chain, with 7 of the top 10 tallest hotels located there. Additionally, it mentions that the crime rate is near 0%, and the income tax rate is also 0%, with 20% of the world's total cranes operating in Dubai. Furthermore, it states that 17% of the population is Emirati, and 83% are immigrants.
#The Dubai Mall is highlighted as the largest shopping mall in the world, with 1200 stores. The infographic also notes that Dubai has no standard address system, with no zip codes, area codes, or postal services. It mentions that the Burj Khalifa is so tall that its residents on top floors need to wait longer to break fast during Ramadan. 
#The infographic also includes information about Dubai's climate-controlled City, with the Royal Suite at Burj Al Arab costing $24,000 per night. Lastly, it notes that the net worth of the four listed billionaires is roughly equal to the GDP of Honduras.

```

</details>


<details>
  <summary>
    <b>æŒ‡ä»¤ç”Ÿæˆç½‘é¡µ</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'A website for Research institutions. The name is Shanghai AI lab. Top Navigation Bar is blue.Below left, an image shows the logo of the lab. In the right, there is a passage of text below that describes the mission of the laboratory.There are several images to show the research projects of Shanghai AI lab.'
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response = model.write_webpage(query, seed=202, task='Instruction-aware Webpage Generation', repetition_penalty=3.0)
print(response)
# see the Instruction-aware Webpage Generation.html 
```
 
See the [Instruction to Webpage](./examples/Instruction-aware_Webpage_Generation.html) results here.
</details>

<details>
  <summary>
    <b>ä¸ªäººä¸»é¡µç”Ÿæˆ</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

## the input should be a resume in markdown format
query = './examples/resume.md'
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response = model.resume_2_webpage(query, seed=202, repetition_penalty=3.0)
print(response)
```
See the [Resume to Webpage](./examples/Resume-to-Personal_Page.html) results here.


</details>


<details>
  <summary>
    <b>æˆªå±ç”Ÿæˆç½‘é¡µ</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'Generate the HTML code of this web image with Tailwind CSS.'
image = ['./examples/screenshot.jpg']
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response = model.resume_2_webpage(query, image, seed=202, repetition_penalty=3.0)
print(response)
```
See the [Screenshot to Webpage](./examples/Screenshot-to-Webpage.html) results here.

</details>



<details>
  <summary>
    <b>Write Artical</b>
  </summary>

```python
import torch
from transformers import AutoModel, AutoTokenizer

torch.set_grad_enabled(False)

# init model and tokenizer
model = AutoModel.from_pretrained('internlm/internlm-xcomposer2d5-7b', torch_dtype=torch.bfloat16, trust_remote_code=True).cuda().eval().half()
tokenizer = AutoTokenizer.from_pretrained('internlm/internlm-xcomposer2d5-7b', trust_remote_code=True)

query = 'é˜…è¯»ä¸‹é¢çš„ææ–™ï¼Œæ ¹æ®è¦æ±‚å†™ä½œã€‚ ç”µå½±ã€Šé•¿å®‰ä¸‰ä¸‡é‡Œã€‹çš„å‡ºç°è®©äººæ„Ÿæ…¨ï¼Œå½±ç‰‡å¹¶æœªå°†é‡ç‚¹å…¨è½åœ¨å¤§å”é£åä¸Šï¼Œä¹Ÿå±•ç°äº†æ¢å¼˜æ°”è±¡çš„é˜´æš—é¢ï¼Œå³æ—§é—¨é˜€çš„èµ„æºå„æ–­ã€æœæ”¿çš„æ—¥ç›Šè¡°è´¥ä¸é’å¹´æ‰ä¿Šçš„å£®å¿—éš¾é…¬ã€‚é«˜é€‚ä»•è¿›æ— é—¨ï¼Œåªèƒ½å›ä¹¡>æ²‰æ½œä¿®è¡Œã€‚æç™½è™½å¾—ç‰çœŸå…¬ä¸»ä¸¾èï¼Œæ“¢å…¥ç¿°æ—ï¼Œä½†ä»–åªæ˜¯æˆä¸ºå”ç„å®—çš„å¾¡ç”¨æ–‡äººï¼Œä¸èƒ½çœŸæ­£å®ç°æœ‰ç›Šäºæœæ”¿çš„å¿—æ„ã€‚ç„¶è€Œï¼Œç‰‡ä¸­é«˜æ½®éƒ¨åˆ†ã€Šå°†è¿›é…’ã€‹ä¸€èŠ‚ï¼Œäººè‡³ä¸­å¹´ã€æŒ‚ç€è‚šè…©çš„æç™½å¼•ä¼—äººä¹˜ä»™é¹¤ä¸Šå¤©ï¼Œä¸€è·¯ä»æ°´é¢ã€ç€‘å¸ƒé£å‡è‡³é“¶æ²³è¿›å…¥ä»™>å®«ï¼Œæç™½ç‹‚å¥”ç€ä¸ä»™äººä»¬ç¢°æ¯ï¼Œæœ€åå¤§å®¶çºµèº«é£å‘æ¼©æ¶¡èˆ¬çš„ä¹é‡å¤©ã€‚è‚‰èº«çš„å¾®è´±ã€ä¸–è·¯çš„â€œå¤©ç”Ÿæˆ‘æå¿…æœ‰ç”¨ï¼Œåå·ï¼Œæ‹˜ä¸ä½ç²¾ç¥çš„é«˜è¹ˆã€‚â€œå¤©ç”Ÿæˆ‘æå¿…æœ‰ç”¨ï¼Œåƒé‡‘æ•£å°½è¿˜å¤æ¥ã€‚â€ å¤å¾€ä»Šæ¥ï¼Œèº«å¤„é—²é¡¿ã€é­å—æŒ«æŠ˜ã€è¢«ç—…ç—›æŠ˜ç£¨ï¼Œå¾ˆå¤šäººéƒ½æ›¾ç»å†>äº†äººç”Ÿçš„â€œå¤±æ„â€ï¼Œå´åè€Œæˆå°±äº†ä»–ä»¬â€œè¯—æ„â€çš„äººç”Ÿã€‚å¯¹æ­£åœ¨è¿½æ±‚äººç”Ÿä»·å€¼çš„å½“ä»£é’å¹´æ¥è¯´ï¼Œå¦‚ä½•å¯¹å¾…äººç”Ÿä¸­çš„ç¼ºæ†¾å’Œå›°é¡¿?è¯—æ„äººç”Ÿä¸­åˆæœ‰æ€æ ·çš„è‡ªæˆ‘åšå®ˆå’Œè‡ªæˆ‘è®¤åŒ?è¯·ç»“åˆâ€œå¤±æ„â€ä¸â€œè¯—æ„â€è¿™ä¸¤ä¸ªå…³é”®è¯å†™ä¸€ç¯‡æ–‡ç« ã€‚ è¦æ±‚:é€‰å‡†è§’åº¦ï¼Œç¡®å®š>ç«‹æ„ï¼Œæ˜ç¡®æ–‡ä½“ï¼Œè‡ªæ‹Ÿæ ‡é¢˜;ä¸è¦å¥—ä½œï¼Œä¸å¾—æŠ„è¢­;ä¸å¾—æ³„éœ²ä¸ªäººä¿¡æ¯;ä¸å°‘äº 800 å­—ã€‚'
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response = model.write_artical(query, seed=8192)
print(response)
#è¯—æ„äººç”Ÿï¼Œè´µåœ¨åšå®ˆ
#ã€Šèœæ ¹è°­ã€‹æœ‰äº‘:â€œé—²æ—¶è¦æœ‰åƒç´§çš„å¿ƒæ€,å¿™é‡Œè¦ç•™åƒé—²å·¥å¤«ã€‚â€äººç”Ÿåœ¨ä¸–,æ€»æœ‰å¤±æ„ä¹‹æ—¶,å½“é¢å¯¹ç¼ºæ†¾å’Œå›°é¡¿,è¯—æ„åœ°ç”Ÿæ´»ç€æ‰èƒ½ä¸ºäººç”Ÿå¢æ·»ä¸€æŠ¹äº®è‰²ã€‚ä½•è°“è¯—æ„åœ°ç”Ÿæ´»? æ‰€è°“è¯—æ„åœ°ç”Ÿæ´»ï¼Œä¾¿æ˜¯åœ¨äºåšå®ˆæœ¬å¿ƒã€ç›´é¢é—æ†¾ã€è¶…è¶Šè‡ªæˆ‘,åœ¨å¤±æ„ä¸­å¯»æ‰¾äººç”Ÿä»·å€¼ã€‚
#è¯—æ„åœ°ç”Ÿæ´»,éœ€åšå®ˆæœ¬å¿ƒ,æ·¡ç„¶å¤„ä¹‹ã€‚
#é™¶æ¸Šæ˜æ›¾æ‰§æ„è¾å»å½­æ³½å¿ä»¤,å½’éšç”°å›­,â€œé‡‡èŠä¸œç¯±ä¸‹,æ‚ ç„¶è§å—å±±â€,åœ¨å±±æ°´é—´å¯„æƒ…è‡ªå¨±ï¼›ç‹ç»´é¢å¯¹ä»•é€”å¤±æ„,ç»ˆæ—¥æ²‰é†‰äºè¯—é…’ä¹‹ä¸­,â€œå…´æ¥æ¯ç‹¬å¾€,èƒœäº‹ç©ºè‡ªçŸ¥â€,åœ¨è¯—é…’ä¸­é—²é€¸è‡ªå¦‚;æç™½ä»•é€”ä¸é¡º,è¢«èµé‡‘æ”¾è¿˜,ä½†ä»–ä¾æ—§è±ªæ°”å¹²äº‘,â€œå¤©ç”Ÿæˆ‘æ‰å¿…æœ‰ç”¨,åƒé‡‘æ•£å°½è¿˜å¤æ¥â€,åœ¨å¤±æ„ä¸­å¦ç„¶è±è¾¾ã€‚åšå®ˆæœ¬å¿ƒï¼Œä¾¿èƒ½åœ¨é­é‡å¤±æ„ä¹‹æ—¶å®ˆä½è‡ªå·±çš„ç²¾ç¥å®¶å›­,è®©ç”Ÿæ´»å……æ»¡è¯—æ„ã€‚åä¹‹,è‹¥ä¸èƒ½åšå®ˆæœ¬å¿ƒ,è€Œåªæ˜¯ä¸€å‘³è¿åˆä¸–ä¿—ä»¥æ±‚å¾—å‡è¿,é‚£çºµä½¿èº«å±…é«˜ä½,äº¦ä¼šä¸§å¤±ç”Ÿæ´»çš„ä¹è¶£ã€‚
#è¯—æ„åœ°ç”Ÿæ´»,éœ€ç›´é¢é—æ†¾,è¶…è¶Šè‡ªæˆ‘ã€‚
#â€œè¥¿å¡å±±å‰ç™½é¹­é£,æ¡ƒèŠ±æµæ°´é³œé±¼è‚¥ã€‚é’ç®¬ç¬ ,ç»¿æŸ³æ,åŠæ–¤é…’,ä¸€çº¶ä¸ã€‚äº”æ¹–å››æµ·çš†å¦‚æ­¤,ä½•å¦¨åˆ°æ­¤å¤„å½’ã€‚â€ç™½å±…æ˜“çš„ã€Šæ¸”æ­Œå­ã€‹å†™å‡ºäº†å¤šå°‘äººçš„æ„¿æœ›:æ²¡æœ‰æƒåŠ¿çº·æ‰°,æ²¡æœ‰è´«å›°å‡„å‡‰,åªæœ‰é’å±±ç»¿æ°´ã€ç™½é¹­é¸¥é¸Ÿä½œä¼´,å¦‚æ­¤è‡ªç”±è‡ªåœ¨çš„ç”Ÿæ´»ä»¤äººç¥å¾€ã€‚ç„¶è€Œ,ç™½å±…æ˜“å´å¹¶æ²¡æœ‰å› æ­¤çœŸçš„å½’éšå±±æ—,è€Œæ˜¯ç›´é¢äººç”Ÿ,è¶…è¶Šè‡ªæˆ‘,å†™ä¸‹äº†ä¸€é¦–é¦–è¯—æ„è€Œå¯Œæœ‰ç°å®å…³æ€€çš„ä½œå“ã€‚å¦‚æœç™½å±…æ˜“åªé¡¾é€ƒé¿äººç”Ÿ,é‚£åˆæ€ä¼šæ‹¥æœ‰â€œå¤§å¼¦å˜ˆå˜ˆå¦‚æ€¥é›¨,å°å¼¦åˆ‡åˆ‡å¦‚ç§è¯­â€çš„ç»ç¾æ¯”å–»å‘¢?å¦‚æœç™½å±…æ˜“åªé¡¾å½’éšå±±æ—,é‚£åˆæ€ä¼šå†™å‡ºâ€œæ­¤æ›²åªåº”å¤©ä¸Šæœ‰,äººé—´å“ªå¾—é…ç™½å±…æ˜“â€è¿™æ ·çš„è¯—å¥å‘¢?
#è¯—æ„åœ°ç”Ÿæ´»,éœ€ç›´é¢é—æ†¾,åšå®ˆæœ¬å¿ƒã€‚
#ææ–‡æ³¢æ‚£æœ‰æ¸å†»ç—‡,åŒ»ç”Ÿè¯´ä»–æ´»ä¸è¿‡äº”å¹´,ä½†ä»–æ²¡æœ‰å› æ­¤æ”¾å¼ƒå¯¹éŸ³ä¹çš„çƒ­çˆ±,è€Œæ˜¯ä¸ç—…é­”ä½œæ–—äº‰,æ¼”å¥å‡ºç¾å¦™çš„ä¹æ›²;å­™å®¶æ—è‡ªå¹¼æ‚£æœ‰è„‘ç˜«,ä½†ä»–ä¸ç”˜äºå‘½è¿çš„æ‰å¼„,ç»ˆæˆå…¨å›½æœ€ç¾æ•™å¸ˆ;å²é“ç”Ÿé¥±å—ç–¾ç—…æŠ˜ç£¨,ä½†ä»–ä»èƒ½å‘å‡ºâ€œæˆ‘å¸¸å¸¸åœ¨æˆ‘çš„å¿ƒå¤´æ¸…ç‚¹,æˆ‘æœ‰ä»€ä¹ˆ?â€çš„å©é—®,å¹¶ç”±æ­¤èµ°ä¸Šæ–‡å­¦é“è·¯,ä¸ºåä¸–ç•™ä¸‹ä¸°åšçš„æ–‡åŒ–é—äº§ã€‚è¿™äº›äººæ²¡æœ‰é€ƒé¿,è€Œæ˜¯é€‰æ‹©ç›´é¢äººç”Ÿçš„ç¼ºæ†¾,åœ¨åšå®ˆæœ¬å¿ƒçš„åŒæ—¶è¶…è¶Šè‡ªæˆ‘,æœ€ç»ˆå®ç°äº†è‡ªå·±çš„ä»·å€¼ã€‚
#è¯—æ„åœ°ç”Ÿæ´»,æ˜¯äºå¤±æ„ä¸­åšå®ˆæœ¬å¿ƒ,äºç¼ºæ†¾ä¸­è¶…è¶Šè‡ªæˆ‘ã€‚å½“é¢å¯¹äººç”Ÿçš„ç¼ºæ†¾ä¸æŒ«æŠ˜,åšå®ˆæœ¬å¿ƒã€è¶…è¶Šè‡ªæˆ‘çš„åŒæ—¶,ä¹Ÿå¿…å°†ä¹¦å†™å±äºè‡ªå·±çš„è¾‰ç…Œç¯‡ç« ã€‚
#æ„¿ä½ æˆ‘éƒ½èƒ½è¯—æ„åœ°ç”Ÿæ´»ç€!

query = 'Please write a blog based on the title: French Pastries: A Sweet Indulgence'
with torch.autocast(device_type='cuda', dtype=torch.float16):
    response = model.write_artical(query, seed=8192)
print(response)
#French Pastries: A Sweet Indulgence
#The French are well known for their love of pastries, and itâ€™s a love that is passed down through generations. When one visits France, they are treated to an assortment of baked goods that can range from the delicate macaron to the rich and decadent chocolate mousse. While there are many delicious types of pastries found in France, five stand out as being the most iconic. Each of these pastries has its own unique qualities that make it special.
#1. Croissant
#One of the most famous pastries from France is the croissant. It is a buttery, flaky pastry that is best enjoyed fresh from the bakery. The dough is laminated with butter, giving it its signature layers. Croissants are typically eaten for breakfast or brunch, often accompanied by coffee or hot chocolate.
#2. Macaron
#The macaron is a small, delicate French confection made from almond flour, powdered sugar, and egg whites. The macaron itself is sandwiched with a ganache or jam filling. They come in a variety of colors and flavors, making them a popular choice for both casual snacking and upscale desserts.
#3. Madeleine
#The madeleine is a small shell-shaped cake that is light and sponge-like. It is often flavored with lemon or orange zest and sometimes dipped in chocolate. Madeleines are perfect for an afternoon snack with tea or coffee.
#4. Ã‰clair
#The Ã©clair is a long, thin pastry filled with cream and topped with chocolate glaze. It is a classic French treat that is both sweet and satisfying. Ã‰clairs can be found in bakeries all over France and are often enjoyed with a cup of hot chocolate.
#5. Tarte Tatin
#The tarte Tatin is an apple tart that is known for its caramelized apples and puff pastry crust. It is named after the Tatin sisters who created the recipe in the late 19th century. Tarte Tatin is best served warm with a scoop of vanilla ice cream.
#These pastries are just a few of the many delicious treats that France has to offer. Whether you are a seasoned traveler or a first-time visitor, indulging in French pastries is a must-do activity. So go ahead, treat yourselfâ€”you deserve it!
```

</details>


## å¤šGPUæµ‹è¯•
å¦‚æœä½ æœ‰å¤šå¼  GPUï¼Œä½†æ˜¯æ¯å¼  GPU çš„æ˜¾å­˜å¤§å°éƒ½ä¸è¶³ä»¥å®¹çº³å®Œæ•´çš„æ¨¡å‹ï¼Œé‚£ä¹ˆå¯ä»¥å°†æ¨¡å‹åˆ‡åˆ†åœ¨å¤šå¼ GPUä¸Šã€‚é¦–å…ˆå®‰è£… accelerate: pip install accelerateï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡ŒèŠå¤©ï¼š
```
# chat with 2 GPUs
python examples/example_chat.py --num_gpus 2
```

## ä½¿ç”¨ LMDeploy åŠ é€Ÿæ¨ç†

å‡†å¤‡ä¸­

## 4-Bit é‡åŒ–æ¨¡å‹

å‡†å¤‡ä¸­

## å¾®è°ƒä»£ç 

è¯·å‚è€ƒ [å¾®è°ƒæŒ‡å—](finetune/README_zh-CN.md)

## Web UI
å‡†å¤‡ä¸­

<br>

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬æ¨¡å‹/ä»£ç /æŠ€æœ¯æŠ¥å‘Šå¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ â­ å’Œ å¼•ç”¨ ğŸ“ï¼Œè°¢è°¢ :)
```BibTeX
@article{internlmxcomposer2_4khd,
      title={InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD},
      author={Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Bin Wang and Linke Ouyang and Songyang Zhang and Haodong Duan and Wenwei Zhang and Yining Li and Hang Yan and Yang Gao and Zhe Chen and Xinyue Zhang and Wei Li and Jingwen Li and Wenhai Wang and Kai Chen and Conghui He and Xingcheng Zhang and Jifeng Dai and Yu Qiao and Dahua Lin and Jiaqi Wang},
      journal={arXiv preprint arXiv:2404.06512},
      year={2024}
}
```

```BibTeX
@article{internlmxcomposer2,
      title={InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model},
      author={Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Bin Wang and Linke Ouyang and Xilin Wei and Songyang Zhang and Haodong Duan and Maosong Cao and Wenwei Zhang and Yining Li and Hang Yan and Yang Gao and Xinyue Zhang and Wei Li and Jingwen Li and Kai Chen and Conghui He and Xingcheng Zhang and Yu Qiao and Dahua Lin and Jiaqi Wang},
      journal={arXiv preprint arXiv:2401.16420},
      year={2024}
}
```

```BibTeX
@article{internlmxcomposer,
      title={InternLM-XComposer: A Vision-Language Large Model for Advanced Text-image Comprehension and Composition},
      author={Pan Zhang and Xiaoyi Dong and Bin Wang and Yuhang Cao and Chao Xu and Linke Ouyang and Zhiyuan Zhao and Shuangrui Ding and Songyang Zhang and Haodong Duan and Wenwei Zhang and Hang Yan and Xinyue Zhang and Wei Li and Jingwen Li and Kai Chen and Conghui He and Xingcheng Zhang and Yu Qiao and Dahua Lin and Jiaqi Wang},
      journal={arXiv preprint arXiv:2309.15112},
      year={2023}
}
```

<br>

## è®¸å¯è¯ & è”ç³»æˆ‘ä»¬

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚
